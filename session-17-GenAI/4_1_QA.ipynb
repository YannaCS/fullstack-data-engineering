{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Preparation\n",
    "\n",
    "## Key Interview Questions & Answers\n",
    "\n",
    "### Architecture Questions\n",
    "\n",
    "**Q: \"Walk me through your RAG architecture end-to-end.\"**\n",
    "\n",
    "A: \"Our system has three main stages:\n",
    "1. **Ingestion**: Documents are chunked using semantic chunking, then embedded using [model]. Chunks are stored in a vector database with BM25 index.\n",
    "2. **Retrieval**: On query, we do hybrid search combining BM25 (keyword) and semantic search, fuse results with RRF, then rerank with a cross-encoder.\n",
    "3. **Generation**: Retrieved chunks are formatted into context, passed to the LLM with the query, and the response is generated with citations.\"\n",
    "\n",
    "**Q: \"What makes your system 'advanced' compared to basic RAG?\"**\n",
    "\n",
    "A: \"Three key improvements:\n",
    "1. **Hybrid search** catches both exact matches (BM25) and semantic similarity\n",
    "2. **Reranking** improves precision by considering query-chunk interaction\n",
    "3. **Agentic capability** lets the LLM decide when to use RAG vs. direct answering\"\n",
    "\n",
    "### Technical Deep-dives\n",
    "\n",
    "**Q: \"Why did you choose your chunking strategy?\"**\n",
    "\n",
    "A: \"We use [semantic/recursive] chunking because:\n",
    "- Preserves semantic coherence within chunks\n",
    "- Handles variable document structures\n",
    "- Chunk size of ~500 tokens balances context and precision\"\n",
    "\n",
    "**Q: \"How do you handle the 'lost in the middle' problem?\"**\n",
    "\n",
    "A: \"LLMs often miss information in the middle of long contexts. We:\n",
    "- Limit context to most relevant chunks\n",
    "- Order chunks strategically (important first/last)\n",
    "- Use reranking to ensure top chunks are most relevant\"\n",
    "\n",
    "**Q: \"What is an AI Agent in your system?\"**\n",
    "\n",
    "A: \"An agent is LLM + Tools + Decision capability. Our agent has access to:\n",
    "- RAG search tool for document queries\n",
    "- [Other tools if applicable]\n",
    "The agent decides when to call each tool based on the query.\"\n",
    "\n",
    "### Evaluation Questions\n",
    "\n",
    "**Q: \"How do you evaluate your RAG system?\"**\n",
    "\n",
    "A: \"We evaluate both retrieval and generation:\n",
    "- **Retrieval**: Recall@k, Precision@k, MRR\n",
    "- **Generation**: LLM-as-a-judge for faithfulness, relevance, helpfulness\n",
    "- **Debugging**: If answers are bad, we first check retrieval, then generation\"\n",
    "\n",
    "## Resume Bullet Templates\n",
    "\n",
    "```text\n",
    "• Designed and implemented Advanced RAG system with hybrid search \n",
    "  (BM25 + semantic), achieving [X]% improvement in retrieval accuracy\n",
    "\n",
    "• Built agentic AI system using [OpenAI/Anthropic] tool use, enabling \n",
    "  dynamic tool selection based on query analysis\n",
    "\n",
    "• Implemented evaluation pipeline using LLM-as-a-judge framework, \n",
    "  measuring faithfulness, relevance, and helpfulness metrics\n",
    "\n",
    "• Optimized chunking strategy using [semantic/recursive] approach, \n",
    "  improving context relevance by [X]%\n",
    "\n",
    "• Integrated cross-encoder reranking to improve precision of retrieved \n",
    "  documents from [X]% to [Y]%\n",
    "```\n",
    "\n",
    "## Concepts to Know Cold\n",
    "\n",
    "| Concept | One-liner |\n",
    "|---------|-----------|\n",
    "| **RAG** | Retrieve relevant context, then generate with it |\n",
    "| **Chunking** | Break documents into searchable pieces |\n",
    "| **Embeddings** | Dense vector representations of text |\n",
    "| **BM25** | Keyword-based sparse retrieval |\n",
    "| **Semantic Search** | Meaning-based dense retrieval |\n",
    "| **RRF** | Combines multiple ranked lists fairly |\n",
    "| **Reranking** | Second-pass scoring for precision |\n",
    "| **Agent** | LLM + Tools + Decision capability |\n",
    "| **ReAct** | Thought → Action → Observation loop |\n",
    "| **MCP** | Standard protocol for tool exposure |\n",
    "| **SFT** | Supervised learning on examples |\n",
    "| **DPO** | Learning from preference pairs |\n",
    "| **LoRA** | Parameter-efficient fine-tuning |\n",
    "| **LLM-as-Judge** | Using LLM to evaluate outputs |\n",
    "\n",
    "\n",
    "\n",
    "## The Project Positioning\n",
    "\n",
    "> **\"Advanced RAG Agent Chat System\"** — A production-ready AI project combining:\n",
    "> - Hybrid search (BM25 + semantic)\n",
    "> - Reranking for precision\n",
    "> - Agentic tool use\n",
    "> - Evaluation capabilities\n",
    "\n",
    "The Full Pipeline\n",
    "\n",
    "```text\n",
    "┌──────────────────────────────────────────────────────────────────────┐\n",
    "│                    COMPLETE RAG AGENT SYSTEM                         │\n",
    "├──────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│  ┌──────────┐                                                        │\n",
    "│  │   User   │                                                        │\n",
    "│  │  Query   │                                                        │\n",
    "│  └────┬─────┘                                                        │\n",
    "│       │                                                              │\n",
    "│       ▼                                                              │\n",
    "│  ┌────────────────────────────────────────────────────────────┐      │\n",
    "│  │                         AGENT                              │      │\n",
    "│  │  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐       │      │\n",
    "│  │  │   Reason    │──▶│   Decide    │──▶│    Act      │       │      │\n",
    "│  │  │  (Thought)  │   │(Tool Select)│   │ (Execute)   │       │      │\n",
    "│  │  └─────────────┘   └─────────────┘   └──────┬──────┘       │      │\n",
    "│  └─────────────────────────────────────────────┼──────────────┘      │\n",
    "│                                                │                     │\n",
    "│       ┌────────────────────────────────────────┼──────────────┐      │\n",
    "│       │                                        ▼              │      │\n",
    "│       │  ┌────────────────────────────────────────────────┐   │      │\n",
    "│       │  │              ADVANCED RAG PIPELINE             │   │      │\n",
    "│       │  │                                                │   │      │\n",
    "│       │  │  Query ──▶ Hybrid Search ──▶ RRF ──▶ Rerank    │   │      │\n",
    "│       │  │              │                        │        │   │      │\n",
    "│       │  │         ┌────┴────┐                   │        │   │      │\n",
    "│       │  │         │         │                   │        │   │      │\n",
    "│       │  │       BM25    Semantic                │        │   │      │\n",
    "│       │  │         │         │                   │        │   │      │\n",
    "│       │  │         └────┬────┘                   │        │   │      │\n",
    "│       │  │              ▼                        ▼        │   │      │\n",
    "│       │  │        Vector DB              Cross-Encoder    │   │      │\n",
    "│       │  └────────────────────────────────────────────────┘   │      │\n",
    "│       │                          TOOLS                        │      │\n",
    "│       └───────────────────────────────────────────────────────┘      │\n",
    "│                                                                      │\n",
    "│       ┌───────────────────────────────────────────────────────┐      │\n",
    "│       │                     GENERATION                        │      │\n",
    "│       │  Context + Query ──▶ LLM ──▶ Response with Citations  │      │\n",
    "│       └───────────────────────────────────────────────────────┘      │\n",
    "│                                                                      │\n",
    "│       ┌───────────────────────────────────────────────────────┐      │\n",
    "│       │                     EVALUATION                        │      │\n",
    "│       │  • Retrieval: Recall@k, Precision@k, MRR              │      │\n",
    "│       │  • Generation: Faithfulness, Relevance, Helpfulness   │      │\n",
    "│       │  • Method: LLM-as-a-Judge                             │      │\n",
    "│       └───────────────────────────────────────────────────────┘      │\n",
    "│                                                                      │\n",
    "└──────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
