{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Interview Questions\n",
    "\n",
    "### Why did you use LangChain in your project?\n",
    "\n",
    "Rapid prototyping, standard components, built-in streaming, easy integration with multiple vector stores\n",
    "\n",
    "\n",
    "### What's the difference between LangChain RAG and an Agent?\n",
    "\n",
    "RAG: Fixed pipeline (retrieve â†’ generate)   \n",
    "Agent: Dynamic decision-making, can choose tools, self-correct, maintain memory\n",
    "\n",
    "\n",
    "### What is HyDE and why is it useful?\n",
    "\n",
    "Generate hypothetical answer, embed that instead of query. Useful because ideal answers are closer to source docs than vague queries.\n",
    "\n",
    "\n",
    "### What is Hybrid Search?\n",
    "\n",
    "Combining vector (semantic) + keyword (BM25) search, merged via RRF. Gets best of both worlds.\n",
    "\n",
    "\n",
    "### Why use a reranker?\n",
    "\n",
    "Vector distance isn't always semantic relevance. Reranker (cross-encoder/LLM) can catch subtle differences like negation.\n",
    "\n",
    "\n",
    "### Why is your system 'Advanced RAG' not just Top-K?\n",
    "\n",
    "Query optimization, hybrid search, reranking, hallucination checking, citations, multi-stage retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
