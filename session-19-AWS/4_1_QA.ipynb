{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Questions & Answers\n",
    "\n",
    "### Q1: Why is Amazon S3 considered Object Storage instead of a file system?\n",
    "\n",
    "\n",
    "S3 is object storage, not a file system, due to these fundamental differences:\n",
    "\n",
    "| Aspect | File System | S3 Object Storage |\n",
    "|--------|-------------|-------------------|\n",
    "| **Structure** | Hierarchical with directories, inodes | Flat namespace with key-value pairs |\n",
    "| **Operations** | Random read/write, seek, append | Only GET/PUT entire objects |\n",
    "| **Metadata** | Limited (permissions, timestamps) | Rich, custom metadata support |\n",
    "| **Modification** | In-place updates possible | Must replace entire object |\n",
    "| **Locking** | File locks supported | No native locking |\n",
    "| **Path** | Real directory traversal | \"Folders\" are just key prefixes |\n",
    "\n",
    "**Key Point:** You cannot open a file in S3, seek to byte 1000, and modify 10 bytes. You must download the entire object, modify it locally, and upload the new version.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Explain the relationship between Bucket, Object, and Key in S3.\n",
    "\n",
    "In Amazon S3, a bucket is a top-level container, an object is the stored data inside bucket, and the key is the unique identifier that locates the object within the bucket. There is no real directories, only keys with prefixes.\n",
    "\n",
    "1ï¸. Bucket   \n",
    "  - A bucket is the top-level container in S3\n",
    "  - It lives in a single AWS Region\n",
    "  - Bucket names are globally unique\n",
    "  - Used for:\n",
    "    - Organizing data\n",
    "    - Applying policies (bucket policy, access points)\n",
    "    - Managing settings (versioning, lifecycle, encryption)\n",
    "\n",
    "  > ğŸ“¦ Think of a bucket as a root namespace\n",
    "\n",
    "2ï¸. Object  \n",
    "  - An object is the actual data stored in S3\n",
    "  - Each object consists of:\n",
    "    - Data (file contents)\n",
    "    - Metadata\n",
    "    - Key\n",
    "  - Objects are immutable (updates = new object)\n",
    "\n",
    "  > ğŸ“„ Objects are the units of storage\n",
    "\n",
    "3ï¸. Key    \n",
    "  - A key is the unique identifier of an object within a bucket\n",
    "  - It is a string, not a real folder path\n",
    "  - â€œFoldersâ€ in S3 are logical, created by key prefixes\n",
    "\n",
    "  > ğŸ”‘ Key = objectâ€™s full path name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Why can't you update a single row inside a CSV file stored in S3?\n",
    "\n",
    "S3 is **immutable object storage**. When you store a CSV file, it becomes a single binary blob (object). S3 has no understanding of:\n",
    "- Row structure\n",
    "- CSV format\n",
    "- Line boundaries\n",
    "\n",
    "**To modify one row, you must:**\n",
    "1. Download the entire CSV file\n",
    "2. Parse it locally (e.g., with pandas)\n",
    "3. Modify the specific row\n",
    "4. Upload the complete new file\n",
    "5. The new upload replaces the old object (or creates a new version)\n",
    "\n",
    "**This is why data lakes often use:**\n",
    "- **Parquet** format with partitioning for efficient updates\n",
    "- **Delta Lake / Iceberg** for ACID transactions on S3\n",
    "- **Append-only patterns** rather than updates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: What is an S3 prefix, and why is it important for Spark/Hive performance?\n",
    "\n",
    "\n",
    "A **prefix** is the \"folder-like\" portion of an object key before the actual filename.\n",
    "\n",
    "**Why it matters for performance:**\n",
    "\n",
    "```text\n",
    "Without Prefix Partitioning:\n",
    "Query: SELECT * FROM sales WHERE date = '2024-01-15'\n",
    "â†’ Spark must scan ALL files: s3://bucket/*.parquet\n",
    "â†’ Full table scan!\n",
    "\n",
    "With Prefix Partitioning:\n",
    "s3://bucket/year=2024/month=01/day=15/*.parquet\n",
    "Query: SELECT * FROM sales WHERE date = '2024-01-15'\n",
    "â†’ Spark only reads: s3://bucket/year=2024/month=01/day=15/\n",
    "â†’ Partition pruning! Only relevant data scanned.\n",
    "```\n",
    "\n",
    "**Performance Benefits:**\n",
    "1. **Partition Pruning**: Read only relevant \"directories\"\n",
    "2. **Parallelism**: Spark reads different prefixes in parallel\n",
    "3. **Reduced I/O**: Less data transferred from S3\n",
    "4. **Cost Savings**: Fewer S3 GET requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Compare IAM Policy, Bucket Policy, and Access Point Policy.\n",
    "\n",
    "\n",
    "| Comparison | IAM Policy | Bucket Policy | Access Point Policy |\n",
    "|------------|-----------|---------------|---------------------|\n",
    "| **Attachment** | IAM user/role/group | S3 bucket | S3 access point |\n",
    "| **Scope** | What this identity can do | Who can access this bucket | Who can access via this AP |\n",
    "| **Principal** | Implicit (attached entity) | Explicit (specified in policy) | Explicit (specified in policy) |\n",
    "| **Cross-Account** | Requires bucket policy too | Can grant alone | Can grant alone |\n",
    "| **Scale** | Per-user management | Single policy per bucket | One policy per access point |\n",
    "| **Best For** | Internal users | Public access, compliance | Large-scale, multi-team |\n",
    "\n",
    "**Access Decision:**\n",
    "```text\n",
    "Access Granted IF:\n",
    "(IAM Policy ALLOWS) AND (Bucket/AP Policy ALLOWS) AND (No Explicit DENY)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: What problem does S3 Versioning solve, and what new problem does it introduce?\n",
    "\n",
    "\n",
    "**Problems SOLVED:**\n",
    "\n",
    "| Problem | How Versioning Solves It |\n",
    "|---------|-------------------------|\n",
    "| Accidental deletion | Delete adds marker, original versions preserved |\n",
    "| Accidental overwrite | Previous versions retained |\n",
    "| Ransomware | Malicious encryption creates new version, originals safe |\n",
    "| Audit requirements | Version history provides change tracking |\n",
    "| Recovery | Can restore any previous version |\n",
    "\n",
    "**Problems INTRODUCED:**\n",
    "\n",
    "| New Problem | Impact | Mitigation |\n",
    "|-------------|--------|------------|\n",
    "| Increased storage costs | All versions stored and billed | Lifecycle rules to expire old versions |\n",
    "| Management complexity | Many versions to track | S3 Inventory to audit |\n",
    "| Delete marker accumulation | Clutters namespace | Lifecycle rule to expire delete markers |\n",
    "| Replication complexity | Must handle version IDs | Configure replication properly |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: What is the difference between SRR and CRR in S3 replication?\n",
    "\n",
    "\n",
    "\n",
    "| Aspect | SRR (Same-Region Replication) | CRR (Cross-Region Replication) |\n",
    "|--------|-------------------------------|--------------------------------|\n",
    "| **Geography** | Source and destination in SAME region | Source and destination in DIFFERENT regions |\n",
    "| **Latency** | Lower (same region) | Higher (cross-region transfer) |\n",
    "| **Cost** | No data transfer charges | Inter-region data transfer charges |\n",
    "| **DR Scope** | Single region failures only | Survives entire region failure |\n",
    "| **Use Cases** | Log aggregation, compliance copies, test environments | Disaster recovery, global access, compliance |\n",
    "| **Network** | Uses AWS backbone, same region | Uses AWS global network |\n",
    "\n",
    "**Common Requirements for Both:**\n",
    "- Versioning must be enabled on both buckets\n",
    "- Proper IAM permissions configured\n",
    "- Bucket owner must have access to both buckets\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Coding Exercise\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Given the `orders` table:\n",
    "```sql\n",
    "orders (\n",
    "    order_id STRING,\n",
    "    user_id STRING,\n",
    "    order_date DATE,\n",
    "    amount DOUBLE,\n",
    "    country STRING\n",
    ")\n",
    "```\n",
    "\n",
    "**Write a query to calculate::**\n",
    "For each country in 2024   \n",
    "1. Find users who placed at least 3 orders\n",
    "2. Calculate total order amount from those qualified users\n",
    "\n",
    "**Expected Output:**\n",
    "```text\n",
    "country | qualified_user_count | total_amount\n",
    "```\n",
    "\n",
    "## Solution\n",
    "\n",
    "```sql\n",
    "-- Solution using CTE (Common Table Expression)\n",
    "WITH qualified_users AS (\n",
    "    -- Step 1: Find users with at least 3 orders per country in 2024\n",
    "    SELECT \n",
    "        country,\n",
    "        user_id,\n",
    "        COUNT(*) AS order_count,\n",
    "        SUM(amount) AS user_total_amount\n",
    "    FROM orders\n",
    "    WHERE YEAR(order_date) = 2024\n",
    "    GROUP BY country, user_id\n",
    "    HAVING COUNT(*) >= 3\n",
    ")\n",
    "-- Step 2: Aggregate by country\n",
    "SELECT \n",
    "    country,\n",
    "    COUNT(DISTINCT user_id) AS qualified_user_count,\n",
    "    SUM(user_total_amount) AS total_amount\n",
    "FROM qualified_users\n",
    "GROUP BY country\n",
    "ORDER BY country;\n",
    "```\n",
    "\n",
    "## Alternative Solution (Subquery)\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    country,\n",
    "    COUNT(*) AS qualified_user_count,\n",
    "    SUM(user_amount) AS total_amount\n",
    "FROM (\n",
    "    SELECT \n",
    "        country,\n",
    "        user_id,\n",
    "        SUM(amount) AS user_amount\n",
    "    FROM orders\n",
    "    WHERE YEAR(order_date) = 2024\n",
    "    GROUP BY country, user_id\n",
    "    HAVING COUNT(*) >= 3\n",
    ") qualified_users\n",
    "GROUP BY country\n",
    "ORDER BY country;\n",
    "```\n",
    "\n",
    "## Explanation\n",
    "\n",
    "```\n",
    "Step-by-Step Logic:\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Step 1: Filter to 2024 orders                               â”‚\n",
    "â”‚ WHERE YEAR(order_date) = 2024                               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Step 2: Group by country AND user_id                        â”‚\n",
    "â”‚ Count orders and sum amounts per user per country           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Step 3: Filter to users with >= 3 orders                    â”‚\n",
    "â”‚ HAVING COUNT(*) >= 3                                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Step 4: Aggregate by country                                â”‚\n",
    "â”‚ Count qualified users, sum their total amounts              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Sample Data & Expected Results\n",
    "\n",
    "```\n",
    "Sample Input:\n",
    "| order_id | user_id | order_date | amount | country |\n",
    "|----------|---------|------------|--------|---------|\n",
    "| 1        | U1      | 2024-01-01 | 100    | USA     |\n",
    "| 2        | U1      | 2024-02-01 | 150    | USA     |\n",
    "| 3        | U1      | 2024-03-01 | 200    | USA     |\n",
    "| 4        | U2      | 2024-01-15 | 50     | USA     |\n",
    "| 5        | U3      | 2024-01-01 | 300    | UK      |\n",
    "| 6        | U3      | 2024-02-01 | 400    | UK      |\n",
    "| 7        | U3      | 2024-03-01 | 500    | UK      |\n",
    "\n",
    "Expected Output:\n",
    "| country | qualified_user_count | total_amount |\n",
    "|---------|---------------------|--------------|\n",
    "| UK      | 1                   | 1200         |\n",
    "| USA     | 1                   | 450          |\n",
    "\n",
    "Explanation:\n",
    "- USA: U1 has 3 orders (qualified), U2 has 1 order (not qualified)\n",
    "- UK: U3 has 3 orders (qualified)\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
