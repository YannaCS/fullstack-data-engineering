{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6327a0f9-9430-46ff-bc10-786c27b99d3c",
   "metadata": {},
   "source": [
    "# AWS Lambda\n",
    "\n",
    "AWS Lambda is a serverless compute service that runs code in response to events without requiring you to provision or manage servers.\n",
    "\n",
    "## Key Characteristics\n",
    "\n",
    "**No servers to manage**: Lambda automatically handles all the infrastructure, including server provisioning, scaling, and maintenance. You only need to upload your code.\n",
    "\n",
    "**Pay only for execution time**: You are charged based on the number of requests and the compute time consumed. When your code isn't running, you pay nothing.\n",
    "\n",
    "**Event-driven**: Lambda functions are triggered by events from various AWS services or custom applications. The function executes only when an event occurs.\n",
    "\n",
    "**Automatically scales**: Lambda automatically scales your application by running code in response to each trigger. Your code runs in parallel and processes each trigger individually.\n",
    "\n",
    "## Architecture Example\n",
    "\n",
    "```text\n",
    "S3 → SNS → SQS (queue)\n",
    "        ↓\n",
    "    (10 messages: \"angeltech.csv uploaded\")\n",
    "        ↓\n",
    "    Lambda (checks queue, processes messages)\n",
    "        ↓\n",
    "    S3 → CloudWatch Logs\n",
    "\n",
    "Alternative flow:\n",
    "Multiple sources (5) → SQS (5 messages) → Lambda\n",
    "    → Lambda checks:\n",
    "        1. How many messages in SQS\n",
    "        2. If SQS = 5 messages\n",
    "        3. Trigger downstream service\n",
    "    → EMR Cluster (Airflow DAG for ETL)\n",
    "```\n",
    "\n",
    "## Services That Trigger Lambda Functions\n",
    "\n",
    "Lambda can be triggered by numerous AWS services, including:\n",
    "\n",
    "**Storage & Data Services**:\n",
    "- Amazon S3 (object uploads, deletions)\n",
    "- Amazon DynamoDB (stream changes)\n",
    "\n",
    "**Messaging & Notifications**:\n",
    "- Amazon SNS (pub/sub notifications)\n",
    "- Amazon SQS (queue messages)\n",
    "- Amazon Simple Email Service (incoming emails)\n",
    "\n",
    "**Streaming & Real-time Data**:\n",
    "- Amazon Kinesis Data Firehose\n",
    "- Amazon Kinesis Data Streams\n",
    "\n",
    "**API & Integration**:\n",
    "- Amazon API Gateway (HTTP requests)\n",
    "- AWS IoT Button\n",
    "- Amazon CloudWatch (scheduled events, alarms)\n",
    "- AWS CloudFormation\n",
    "- Amazon Lex (chatbot interactions)\n",
    "- Amazon Cognito (user authentication)\n",
    "- Amazon CloudFront (edge computing)\n",
    "- AWS CodeCommit (code repository changes)\n",
    "- AWS Config (configuration changes)\n",
    "\n",
    "# Lambda Costs\n",
    "\n",
    "## How AWS Lambda Charges\n",
    "\n",
    "Lambda uses a pay-per-use pricing model with three main components:\n",
    "\n",
    "**Pay per request**: Charged by the number of function invocations (how many times your function is executed).\n",
    "\n",
    "**Pay per execution time**: Billed by milliseconds, measured from when your code begins executing until it returns or terminates.\n",
    "\n",
    "**Pay per memory allocation**: CPU power scales proportionally with memory size. More memory means more CPU power but higher cost.\n",
    "\n",
    "## Key Cost Factors\n",
    "\n",
    "**Invocation count**: Total number of times your Lambda function is executed.\n",
    "\n",
    "**Execution duration**: How long your function runs (billed in milliseconds).\n",
    "\n",
    "**Memory configuration**: The amount of memory allocated to your function (128 MB to 10,240 MB).\n",
    "\n",
    "## Important Cost Notes\n",
    "\n",
    "- **No cost when Lambda is not running**: You only pay for actual execution time.\n",
    "- **Short, fast executions are cheaper**: Optimizing your code to run faster reduces costs.\n",
    "- **High-frequency triggers can become expensive**: If your Lambda is triggered millions of times, costs add up despite the low per-request charge.\n",
    "\n",
    "## Pricing Details\n",
    "\n",
    "**Generous Free Tier (per month)**:\n",
    "- 1 million requests\n",
    "- 400,000 GB-seconds of compute time\n",
    "\n",
    "**After Free Tier**:\n",
    "- $0.20 per 1 million requests\n",
    "- $0.00001667 per GB-second\n",
    "\n",
    "## GB-Second Calculation\n",
    "\n",
    "GB-second is calculated as: Memory (in GB) × Execution time (in seconds)\n",
    "\n",
    "**Examples**:\n",
    "\n",
    "Example 1:\n",
    "```text\n",
    "Lambda configuration: 1GB memory, 1 second execution\n",
    "GB-seconds = 1 × 1 = 1 GB-second\n",
    "```\n",
    "\n",
    "Example 2:\n",
    "```text\n",
    "Lambda configuration: 2GB memory, 3 seconds execution\n",
    "GB-seconds = 2 × 3 = 6 GB-seconds\n",
    "```\n",
    "\n",
    "Example 3 (Cost calculation for 1 million invocations):\n",
    "```text\n",
    "Configuration: 1GB memory, 2 seconds execution\n",
    "Per invocation: 1 × 2 = 2 GB-seconds\n",
    "For 1,000,000 invocations: 2 × 1,000,000 = 2,000,000 GB-seconds\n",
    "Cost: 2,000,000 × $0.00001667 = $33.34\n",
    "For 30 days: $33.34 × 30 = $1,000.20\n",
    "```\n",
    "\n",
    "Practice problem:\n",
    "```text\n",
    "Configuration: 512MB memory (0.512 GB), 10 seconds execution\n",
    "GB-seconds per invocation = 0.512 × 10 = 5.12 GB-seconds\n",
    "```\n",
    "\n",
    "# Creating a Lambda Function\n",
    "\n",
    "## Step 1: Choose Creation Method\n",
    "\n",
    "**Author from scratch**: Start with a blank function and write your own code.\n",
    "\n",
    "**Use a blueprint**: Start from a pre-built template for common use cases (e.g., S3 object processing, DynamoDB streams).\n",
    "\n",
    "**Container image**: Deploy your function as a container image (up to 10 GB), useful for complex dependencies.\n",
    "\n",
    "## Step 2: Basic Configuration\n",
    "\n",
    "**Function name**: Give your Lambda function a unique, descriptive name.\n",
    "\n",
    "**Runtime**: Choose the programming language and version:\n",
    "- Python (3.8, 3.9, 3.10, 3.11, etc.)\n",
    "- Node.js\n",
    "- Java\n",
    "- Go\n",
    "- Ruby\n",
    "- .NET Core\n",
    "- Custom runtime\n",
    "\n",
    "**Architecture**: Select the instruction set architecture:\n",
    "- x86_64 (traditional Intel/AMD)\n",
    "- arm64 (AWS Graviton2, often cheaper and more efficient)\n",
    "\n",
    "## Step 3: Permissions\n",
    "\n",
    "**Assign execution role**: Lambda needs an IAM role to execute and access other AWS services.\n",
    "\n",
    "**Grant access to AWS services**: The role must have permissions to interact with services like:\n",
    "- S3 (read/write objects)\n",
    "- SQS (receive/delete messages)\n",
    "- DynamoDB (read/write items)\n",
    "- CloudWatch Logs (write logs)\n",
    "\n",
    "Common managed policies:\n",
    "- `AWSLambdaBasicExecutionRole` (CloudWatch Logs access)\n",
    "- `AWSLambdaVPCAccessExecutionRole` (VPC access)\n",
    "- Custom policies for S3, DynamoDB, SQS, etc.\n",
    "\n",
    "## Step 4: Advanced Options\n",
    "\n",
    "**Durable execution (optional)**: Configure for long-running workflows.\n",
    "\n",
    "**Environment variables**: Store configuration values (API keys, database URLs) as key-value pairs accessible in your code.\n",
    "\n",
    "**Timeout settings**: Maximum execution time (default: 3 seconds, max: 15 minutes/900 seconds).\n",
    "\n",
    "**Memory settings**: Allocate memory from 128 MB to 10,240 MB (CPU scales proportionally).\n",
    "\n",
    "Additional advanced settings:\n",
    "- VPC configuration (for accessing resources in a private network)\n",
    "- File system mounting (EFS)\n",
    "- Concurrency limits\n",
    "- Dead letter queue configuration\n",
    "- Layers (reusable code/dependencies)\n",
    "\n",
    "# Amazon SQS (Simple Queue Service)\n",
    "\n",
    "## What is SQS?\n",
    "\n",
    "Amazon SQS is a fully managed message queue service that enables you to decouple and scale microservices, distributed systems, and serverless applications.\n",
    "\n",
    "**Fully managed**: AWS handles all infrastructure, maintenance, and scaling.\n",
    "\n",
    "**Decouples producers and consumers**: Producers send messages to the queue, consumers retrieve and process them independently. They don't need to communicate directly.\n",
    "\n",
    "## Why Use SQS?\n",
    "\n",
    "**Buffer traffic spikes**: Queue absorbs sudden bursts of requests, preventing downstream systems from being overwhelmed.\n",
    "\n",
    "**Improve system reliability**: If a consumer fails, messages remain in the queue and can be processed later.\n",
    "\n",
    "**Enable asynchronous processing**: Producers don't wait for consumers to finish processing; they continue working independently.\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "**Message**: A unit of data sent to the queue (up to 256 KB). Can contain text, JSON, XML, or any unformatted text.\n",
    "\n",
    "**Queue**: A temporary repository for messages waiting to be processed.\n",
    "\n",
    "**Producer**: The component or service that sends messages to the queue.\n",
    "\n",
    "**Consumer**: The component or service that retrieves and processes messages from the queue.\n",
    "\n",
    "**Visibility Timeout**: When a consumer receives a message, it becomes invisible to other consumers for a specified period (default: 30 seconds). This prevents multiple consumers from processing the same message. If the consumer doesn't delete the message within this timeout, it becomes visible again for reprocessing.\n",
    "\n",
    "## Queue Types\n",
    "\n",
    "### Standard Queue (Default)\n",
    "\n",
    "- Unlimited throughput\n",
    "- Best-effort ordering (messages might arrive out of order)\n",
    "- At-least-once delivery (messages might be delivered more than once)\n",
    "- Available in all AWS regions\n",
    "\n",
    "### FIFO Queue (First In, First Out)\n",
    "\n",
    "- **First in, first out ordering**: Messages are processed in the exact order they're sent.\n",
    "- **Not available in all regions**: Check regional availability.\n",
    "- **Queue name must end with .fifo**: This is a naming requirement (e.g., `my-queue.fifo`).\n",
    "- **Exactly-once processing**: Messages are delivered exactly once and remain available until a consumer processes and deletes them.\n",
    "- **Lower throughput**: Up to 3,000 messages per second with batching (or 300 messages per second without batching).\n",
    "\n",
    "## SQS Limitations\n",
    "\n",
    "**Maximum in-flight messages**: 120,000 messages can be in-flight (received by consumers but not yet deleted) at any time.\n",
    "\n",
    "**Batch request maximum**: 10 messages per batch request, with a total maximum size of 256 KB.\n",
    "\n",
    "**Message content types**: XML, JSON, or unformatted text.\n",
    "\n",
    "**FIFO throughput**: Supports up to 3,000 messages per second using batching.\n",
    "\n",
    "**Maximum message size**: 256 KB per message. For larger payloads, use S3 and send a reference in the message.\n",
    "\n",
    "**Data retention**: Messages can be retained from 1 minute to 14 days (default: 4 days).\n",
    "\n",
    "**Pricing**: Calculated per API request (send, receive, delete) and network data transfer usage.\n",
    "\n",
    "## Common Use Cases\n",
    "\n",
    "- Decoupling microservices\n",
    "- Work queues for distributed systems\n",
    "- Buffering writes to databases\n",
    "- Batch processing\n",
    "- Order processing systems\n",
    "- Fan-out pattern with SNS\n",
    "\n",
    "# Amazon SNS (Simple Notification Service)\n",
    "\n",
    "## What is SNS?\n",
    "\n",
    "Amazon SNS is a fully managed publish-subscribe (pub/sub) messaging service that enables you to send messages to multiple subscribers simultaneously.\n",
    "\n",
    "**Fully managed pub/sub service**: AWS handles all infrastructure and message delivery.\n",
    "\n",
    "**One message → fan-out to multiple subscribers**: A single published message can be delivered to many different endpoints.\n",
    "\n",
    "**Decouples message producers from consumers**: Publishers don't need to know who the subscribers are or how they process messages.\n",
    "\n",
    "## How SNS Works\n",
    "\n",
    "1. Create a **topic** (a logical access point and communication channel)\n",
    "2. **Subscribers** subscribe to the topic\n",
    "3. **Publishers** send messages to the topic\n",
    "4. SNS delivers the message to all subscribers\n",
    "\n",
    "## Common Subscribers\n",
    "\n",
    "SNS can deliver messages to various endpoints:\n",
    "\n",
    "**Email / SMS**: Send notifications to email addresses or mobile phone numbers.\n",
    "\n",
    "**SQS**: Send messages to SQS queues for further processing.\n",
    "\n",
    "**Lambda**: Trigger Lambda functions to execute code in response to messages.\n",
    "\n",
    "**HTTP / HTTPS endpoints**: Send messages to web servers or APIs.\n",
    "\n",
    "**Mobile push notifications**: Send to mobile apps (iOS, Android, etc.).\n",
    "\n",
    "**Application endpoints**: Custom application endpoints.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "**Fan-out pattern**: Publish once, deliver to many subscribers (common pattern: SNS → multiple SQS queues).\n",
    "\n",
    "**Message filtering**: Subscribers can filter messages based on message attributes.\n",
    "\n",
    "**Message attributes**: Add metadata to messages for routing and filtering.\n",
    "\n",
    "**Delivery retry policies**: Automatic retries for failed deliveries.\n",
    "\n",
    "**Dead-letter queues**: Send failed messages to an SQS queue for analysis.\n",
    "\n",
    "## Common Architecture Pattern: SNS + SQS\n",
    "\n",
    "```text\n",
    "Producer → SNS Topic → Multiple SQS Queues → Multiple Lambda Functions\n",
    "```\n",
    "\n",
    "Benefits:\n",
    "- Publish once to SNS\n",
    "- Multiple independent processing pipelines via SQS\n",
    "- Each queue can have different consumers\n",
    "- Fault tolerance (messages persist in SQS)\n",
    "- Independent scaling per consumer\n",
    "\n",
    "# S3 Event-Driven Architecture\n",
    "\n",
    "## What are S3 Events?\n",
    "\n",
    "S3 can emit events when objects are created, modified, or deleted in a bucket. These events can trigger downstream processing in near real-time.\n",
    "\n",
    "## Common S3 Event Types\n",
    "\n",
    "**ObjectCreated events**:\n",
    "- PUT: Object uploaded via PUT request\n",
    "- POST: Object uploaded via POST request\n",
    "- COPY: Object created via copy operation\n",
    "- CompleteMultipartUpload: Large object uploaded in parts\n",
    "\n",
    "**ObjectRemoved events**:\n",
    "- DELETE: Object deleted from bucket\n",
    "- DeleteMarkerCreated: Delete marker added (versioned bucket)\n",
    "\n",
    "**Other event types**:\n",
    "- ObjectRestore: Object restored from Glacier\n",
    "- Replication events: Cross-region replication completed\n",
    "- Object tagging events\n",
    "\n",
    "## Event Destinations\n",
    "\n",
    "S3 events can trigger various AWS services:\n",
    "\n",
    "**AWS Lambda**: Execute code in response to S3 changes (most common pattern).\n",
    "\n",
    "**Amazon SQS**: Send event notifications to a queue for asynchronous processing.\n",
    "\n",
    "**Amazon SNS**: Publish event notifications to multiple subscribers.\n",
    "\n",
    "**EventBridge**: Route events to multiple targets with advanced filtering.\n",
    "\n",
    "## Architecture Diagram\n",
    "\n",
    "```text\n",
    "                    ┌─────────────┐\n",
    "                    │  SNS Topic  │\n",
    "                    └─────────────┘\n",
    "                          ▲\n",
    "                          │\n",
    "                    ┌─────────────┐        ┌──────────────────┐\n",
    "                    │  S3 Bucket  │───────▶│  Router Lambda   │\n",
    "                    └─────────────┘        └──────────────────┘\n",
    "                          │\n",
    "                          │\n",
    "                    ┌─────────────┐\n",
    "                    │  SQS Queue  │\n",
    "                    └─────────────┘\n",
    "```\n",
    "\n",
    "## Typical Use Cases\n",
    "\n",
    "**Trigger data pipelines**: When new data files arrive, automatically start ETL processes.\n",
    "\n",
    "**File-driven ETL**: Process CSV, JSON, or Parquet files as soon as they're uploaded.\n",
    "\n",
    "**Near real-time processing**: Respond to data changes within seconds.\n",
    "\n",
    "**Image/video processing**: Automatically resize images or transcode videos upon upload.\n",
    "\n",
    "**Data validation**: Validate file formats and data quality immediately after upload.\n",
    "\n",
    "**Archival and backup**: Copy files to Glacier or another region automatically.\n",
    "\n",
    "**Audit logging**: Track all object changes for compliance.\n",
    "\n",
    "## Example Flow: S3 → SNS → SQS → Lambda\n",
    "\n",
    "```text\n",
    "1. File uploaded to S3 bucket\n",
    "2. S3 sends event notification to SNS topic\n",
    "3. SNS fans out to multiple SQS queues\n",
    "4. Lambda functions poll SQS queues\n",
    "5. Lambda processes file from S3\n",
    "6. Lambda writes results back to S3\n",
    "7. CloudWatch logs capture execution details\n",
    "```\n",
    "\n",
    "**Benefits of this pattern**:\n",
    "- Decoupling: Components work independently\n",
    "- Buffering: SQS absorbs traffic spikes\n",
    "- Retry logic: Failed messages can be reprocessed\n",
    "- Parallel processing: Multiple Lambdas process different messages\n",
    "- Fan-out: Single S3 event triggers multiple workflows\n",
    "\n",
    "## S3 Event Configuration\n",
    "\n",
    "To set up S3 events:\n",
    "\n",
    "1. Go to S3 bucket properties\n",
    "2. Navigate to \"Event notifications\"\n",
    "3. Create event notification\n",
    "4. Choose event types (ObjectCreated, ObjectRemoved, etc.)\n",
    "5. Add prefix/suffix filters (optional, e.g., only `.csv` files)\n",
    "6. Select destination (Lambda, SQS, SNS)\n",
    "7. Configure destination permissions (Lambda execution role needs S3 read access)\n",
    "\n",
    "# Amazon CloudWatch\n",
    "\n",
    "## What is CloudWatch?\n",
    "\n",
    "Amazon CloudWatch is a monitoring and observability service that provides data and actionable insights for AWS resources and applications.\n",
    "\n",
    "**Monitoring service**: Tracks the health and performance of your AWS infrastructure.\n",
    "\n",
    "**Observability service**: Provides visibility into logs, metrics, and traces across your entire stack.\n",
    "\n",
    "## Core Capabilities\n",
    "\n",
    "**Collects and tracks metrics**: Monitors CPU utilization, network traffic, disk I/O, custom application metrics.\n",
    "\n",
    "**Collects, stores, and searches log files**: Centralized log management from Lambda, EC2, ECS, and other services.\n",
    "\n",
    "**Enables alarms and automated actions**: Trigger notifications or automated responses when thresholds are breached.\n",
    "\n",
    "**Provides visibility**: Unified view of resource health, application performance, and operational status.\n",
    "\n",
    "## Typical CloudWatch Workflow\n",
    "\n",
    "```text\n",
    "1. AWS resources emit metrics & logs\n",
    "   ↓\n",
    "2. CloudWatch collects and stores data\n",
    "   ↓\n",
    "3. CloudWatch evaluates thresholds and conditions\n",
    "   ↓\n",
    "4. Alarms trigger when thresholds are breached\n",
    "   ↓\n",
    "5. Actions are executed:\n",
    "   - Send email via SNS\n",
    "   - Scale resources via Auto Scaling\n",
    "   - Trigger Lambda function\n",
    "   - Post to SNS topic\n",
    "```\n",
    "\n",
    "## CloudWatch Components\n",
    "\n",
    "### Metrics\n",
    "- Data points about resource performance\n",
    "- Examples: CPUUtilization, NetworkIn, DiskReadOps\n",
    "- Can create custom metrics\n",
    "- Stored for 15 months\n",
    "\n",
    "### Logs\n",
    "- Log groups (collection of log streams)\n",
    "- Log streams (sequence of log events from same source)\n",
    "- Log insights (query and analyze logs)\n",
    "- Integration with Lambda, EC2, ECS, etc.\n",
    "\n",
    "### Alarms\n",
    "- Monitor a single metric\n",
    "- Execute actions when thresholds are breached\n",
    "- States: OK, ALARM, INSUFFICIENT_DATA\n",
    "- Can trigger SNS, Auto Scaling, EC2 actions\n",
    "\n",
    "### Dashboards\n",
    "- Customizable views of metrics\n",
    "- Multiple widgets showing different data\n",
    "- Shareable across accounts\n",
    "\n",
    "## CloudWatch in Lambda Context\n",
    "\n",
    "**Automatic log integration**: Every Lambda function automatically sends logs to CloudWatch Logs.\n",
    "\n",
    "**Log groups**: Created automatically with format `/aws/lambda/<function-name>`.\n",
    "\n",
    "**Log streams**: Each Lambda invocation creates a log entry in a stream.\n",
    "\n",
    "**Monitoring Lambda metrics**:\n",
    "- Invocations: Number of times function is executed\n",
    "- Duration: Execution time\n",
    "- Errors: Number of failed invocations\n",
    "- Throttles: Number of throttled invocations\n",
    "- Concurrent executions: Number of function instances running simultaneously\n",
    "- Dead letter queue errors: Messages failed to process\n",
    "\n",
    "**CloudWatch Logs Insights**: Query Lambda logs for debugging and analysis.\n",
    "\n",
    "## Architecture Diagram\n",
    "\n",
    "```text\n",
    "                       ┌─────────────────────────────────────┐\n",
    "                       │      Amazon CloudWatch              │\n",
    "                       │                                     │\n",
    "   ┌──────────────┐    │  ┌──────────┐   ┌──────────────┐  │    ┌─────────┐\n",
    "   │ AWS Resources│───▶│  │ Metrics  │   │  Statistics  │  │───▶│ Actions │\n",
    "   │ (CloudWatch  │    │  └──────────┘   └──────────────┘  │    └─────────┘\n",
    "   │   enabled)   │    │                                     │         │\n",
    "   └──────────────┘    │  ┌──────────────────────────────┐ │         ├──▶ Email\n",
    "                       │  │  Alarms                      │ │         │     (SNS)\n",
    "   ┌──────────────┐    │  │  - CPU > 80%                │ │         │\n",
    "   │ Custom Data  │───▶│  │  - Memory > 90%             │ │         └──▶ Auto\n",
    "   │              │    │  │  - Errors > 5               │ │               Scaling\n",
    "   └──────────────┘    │  └──────────────────────────────┘ │\n",
    "                       │                                     │\n",
    "                       └─────────────────────────────────────┘\n",
    "                                         │\n",
    "                                         ▼\n",
    "                         ┌─────────────────────────────┐\n",
    "                         │  AWS Management Console     │\n",
    "                         │  Statistics Consumer        │\n",
    "                         └─────────────────────────────┘\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bigdata)",
   "language": "python",
   "name": "bigdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
