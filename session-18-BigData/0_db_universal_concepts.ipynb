{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NoSQL Databases\n",
    "\n",
    "<img src=\"./pic/1_nosql_db_types.png\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Stores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MongoDB\n",
    "\n",
    "**What it is:** Document-oriented NoSQL database storing data as flexible JSON-like documents.\n",
    "\n",
    "**Document Structure:**\n",
    "\n",
    "```javascript\n",
    "// MongoDB Document Example\n",
    "{\n",
    "    \"_id\": ObjectId(\"507f1f77bcf86cd799439011\"),\n",
    "    \"customer\": {\n",
    "        \"name\": \"John Doe\",\n",
    "        \"email\": \"john@example.com\",\n",
    "        \"address\": {\n",
    "            \"street\": \"123 Main St\",\n",
    "            \"city\": \"Boston\",\n",
    "            \"state\": \"MA\",\n",
    "            \"zip\": \"02101\"\n",
    "        }\n",
    "    },\n",
    "    \"orders\": [\n",
    "        {\n",
    "            \"order_id\": \"ORD001\",\n",
    "            \"date\": ISODate(\"2024-01-15\"),\n",
    "            \"items\": [\n",
    "                {\"product\": \"Laptop\", \"qty\": 1, \"price\": 999.99},\n",
    "                {\"product\": \"Mouse\", \"qty\": 2, \"price\": 29.99}\n",
    "            ],\n",
    "            \"total\": 1059.97\n",
    "        }\n",
    "    ],\n",
    "    \"tags\": [\"premium\", \"electronics\"],\n",
    "    \"created_at\": ISODate(\"2024-01-01\")\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Flexible Schema** | Documents can have different structures |\n",
    "| **Rich Queries** | Complex queries, aggregation pipeline |\n",
    "| **Indexing** | Secondary indexes, compound indexes, text search |\n",
    "| **Replication** | Replica sets for high availability |\n",
    "| **Sharding** | Horizontal scaling across nodes |\n",
    "\n",
    "**Best For:**\n",
    "- Content management systems\n",
    "- Product catalogs\n",
    "- Real-time analytics\n",
    "- Mobile applications\n",
    "- Rapid prototyping\n",
    "\n",
    "**Document Database Comparison:**\n",
    "| Database | Type | Best For | Key Features |\n",
    "|----------|------|----------|--------------|\n",
    "| **MongoDB** | Document | General purpose | Aggregation, Atlas cloud |\n",
    "| **Couchbase** | Document | Caching + persistence | Memory-first, N1QL |\n",
    "| **Amazon DocumentDB** | Document | MongoDB-compatible | Managed, AWS integrated |\n",
    "| **CouchDB** | Document | Offline-first apps | Multi-master replication |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wide-Column Stores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apache Cassandra\n",
    "\n",
    "**What it is:** Distributed NoSQL database designed for high availability and linear scalability.\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "```text\n",
    "┌────────────────────────────────────────────────────┐\n",
    "│              CASSANDRA RING (No Master!)           │\n",
    "│                                                    │\n",
    "│                    ┌─────┐                         │\n",
    "│               ┌────│Node │────┐                    │\n",
    "│               │    │  A  │    │                    │\n",
    "│               │    └─────┘    │                    │\n",
    "│          ┌─────┐            ┌─────┐                │\n",
    "│          │Node │            │Node │                │\n",
    "│          │  F  │            │  B  │                │\n",
    "│          └─────┘            └─────┘                │\n",
    "│               │    ┌─────┐    │                    │\n",
    "│               │    │Node │    │                    │\n",
    "│               └────│  E  │────┘                    │\n",
    "│          ┌─────┐   └─────┘   ┌─────┐               │\n",
    "│          │Node │◄───────────▶│Node │               │\n",
    "│          │  D  │             │  C  │               │\n",
    "│          └─────┘             └─────┘               │\n",
    "│                                                    │\n",
    "│  All nodes are equal - no single point of failure  │\n",
    "│  Data distributed by partition key hash            │\n",
    "└────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Masterless** | No single point of failure |\n",
    "| **Linear Scalability** | Add nodes = linear performance increase |\n",
    "| **Tunable Consistency** | Choose between consistency and availability |\n",
    "| **Wide Column Store** | Flexible schema per row |\n",
    "| **Multi-Datacenter** | Built-in cross-DC replication |\n",
    "\n",
    "**Best For:**\n",
    "- Time-series data (IoT, logs, metrics)\n",
    "- High-write throughput applications\n",
    "- Geographically distributed systems\n",
    "- Messaging and chat applications\n",
    "\n",
    "**Example CQL:**\n",
    "```sql\n",
    "-- Create keyspace with replication\n",
    "CREATE KEYSPACE ecommerce \n",
    "WITH replication = {\n",
    "    'class': 'NetworkTopologyStrategy',\n",
    "    'datacenter1': 3,\n",
    "    'datacenter2': 2\n",
    "};\n",
    "\n",
    "-- Create table with partition and clustering keys\n",
    "CREATE TABLE ecommerce.orders (\n",
    "    customer_id UUID,\n",
    "    order_date TIMESTAMP,\n",
    "    order_id UUID,\n",
    "    product_name TEXT,\n",
    "    quantity INT,\n",
    "    total DECIMAL,\n",
    "    PRIMARY KEY ((customer_id), order_date, order_id)\n",
    ") WITH CLUSTERING ORDER BY (order_date DESC);\n",
    "\n",
    "-- Insert data\n",
    "INSERT INTO ecommerce.orders \n",
    "    (customer_id, order_date, order_id, product_name, quantity, total)\n",
    "VALUES \n",
    "    (uuid(), toTimestamp(now()), uuid(), 'Laptop', 1, 999.99);\n",
    "\n",
    "-- Query by partition key\n",
    "SELECT * FROM ecommerce.orders \n",
    "WHERE customer_id = 123e4567-e89b-12d3-a456-426614174000;\n",
    "```\n",
    "\n",
    "**Wide-Column Database Comparison:**\n",
    "| Database | Best For | Key Features |\n",
    "|----------|----------|--------------|\n",
    "| **Apache Cassandra** | Write-heavy, time-series | Masterless, linear scale |\n",
    "| **Apache HBase** | Hadoop integration | HDFS-based, strong consistency |\n",
    "| **ScyllaDB** | Cassandra replacement | C++ rewrite, 10x faster |\n",
    "| **Google Bigtable** | Managed wide-column | GCP native, Petabyte scale |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key-Value Stores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Redis\n",
    "\n",
    "**What it is:** In-memory data structure store used as database, cache, and message broker.\n",
    "\n",
    "**Data Structures:**\n",
    "\n",
    "```text\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│                     REDIS DATA TYPES                       │\n",
    "├────────────────────────────────────────────────────────────┤\n",
    "│  STRING          HASH              LIST                    │\n",
    "│  key → \"value\"   key → {f1:v1,     key → [a, b, c, d]      │\n",
    "│                        f2:v2}                              │\n",
    "│                                                            │\n",
    "│  SET             SORTED SET        STREAM                  │\n",
    "│  key → {a,b,c}   key → {a:1,       key → [(id,{data}),...] │\n",
    "│                        b:2,c:3}                            │\n",
    "│                                                            │\n",
    "└────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Sub-millisecond Latency** | All data in memory |\n",
    "| **Rich Data Structures** | Strings, hashes, lists, sets, sorted sets |\n",
    "| **Pub/Sub** | Message broker capabilities |\n",
    "| **Persistence** | RDB snapshots, AOF logging |\n",
    "| **Clustering** | Horizontal scaling |\n",
    "| **Lua Scripting** | Server-side logic |\n",
    "\n",
    "**Best For:**\n",
    "- Caching (session, query results)\n",
    "- Real-time leaderboards\n",
    "- Rate limiting\n",
    "- Message queues\n",
    "- Real-time analytics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Amazon DynamoDB\n",
    "\n",
    "**What it is:** Fully managed, serverless NoSQL database with single-digit millisecond performance.\n",
    "\n",
    "**Key Concepts:**\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Partition Key** | Primary key for data distribution |\n",
    "| **Sort Key** | Optional secondary key for ordering |\n",
    "| **GSI** | Global Secondary Index for alternate queries |\n",
    "| **LSI** | Local Secondary Index (same partition) |\n",
    "\n",
    "**Capacity Modes:**\n",
    "| Mode | Description | Best For |\n",
    "|------|-------------|----------|\n",
    "| **On-Demand** | Pay per request | Unpredictable workloads |\n",
    "| **Provisioned** | Set RCU/WCU | Predictable workloads |\n",
    "| **Reserved** | Committed capacity | Steady-state, cost savings |\n",
    "\n",
    "**Key-Value Database Comparison:**\n",
    "| Database | Type | Best For | Latency |\n",
    "|----------|------|----------|---------|\n",
    "| **Redis** | In-Memory | Caching, real-time | Sub-ms |\n",
    "| **Memcached** | In-Memory | Simple caching | Sub-ms |\n",
    "| **DynamoDB** | Managed | Serverless apps | Single-digit ms |\n",
    "| **etcd** | Distributed | Config, service discovery | Low |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Databases\n",
    "\n",
    "##### Neo4j\n",
    "\n",
    "**What it is:** Native graph database optimized for connected data.\n",
    "\n",
    "**Graph Structure:**\n",
    "\n",
    "```text\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│                      GRAPH DATABASE                        │\n",
    "├────────────────────────────────────────────────────────────┤\n",
    "│        ┌──────────┐                    ┌──────────┐        │\n",
    "│        │  Alice   │───FRIENDS_WITH────▶│   Bob    │        │\n",
    "│        │  (User)  │                    │  (User)  │        │\n",
    "│        └────┬─────┘                    └────┬─────┘        │\n",
    "│         PURCHASED                       PURCHASED          │\n",
    "│             │                               │              │\n",
    "│             ▼                               ▼              │\n",
    "│        ┌──────────┐                    ┌──────────┐        │\n",
    "│        │  Laptop  │◀───SIMILAR_TO─────▶│  Tablet  │        │\n",
    "│        │(Product) │                    │(Product) │        │\n",
    "│        └──────────┘                    └──────────┘        │\n",
    "│  Cypher Query: \"Find friends who bought similar products\"  │\n",
    "│  MATCH (u:User)-[:FRIENDS_WITH]->(friend:User)             │\n",
    "│  MATCH (u)-[:PURCHASED]->(p:Product)                       │\n",
    "│  MATCH (friend)-[:PURCHASED]->(p2:Product)                 │\n",
    "│  WHERE (p)-[:SIMILAR_TO]-(p2)                              │\n",
    "│  RETURN friend, p2                                         │\n",
    "└────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Best For:**\n",
    "- Social networks\n",
    "- Recommendation engines\n",
    "- Fraud detection\n",
    "- Knowledge graphs\n",
    "- Network/IT operations\n",
    "\n",
    "**Graph Database Comparison:**\n",
    "| Database | Type | Best For | Query Language |\n",
    "|----------|------|----------|----------------|\n",
    "| **Neo4j** | Native Graph | General purpose | Cypher |\n",
    "| **Amazon Neptune** | Managed | AWS integration | Gremlin, SPARQL |\n",
    "| **JanusGraph** | Distributed | Massive scale | Gremlin |\n",
    "| **TigerGraph** | Distributed | Real-time analytics | GSQL |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Relational Databases (OLTP)\n",
    "\n",
    "```text\n",
    "PURPOSE: Run your business operations\n",
    "\n",
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│  User clicks \"Buy Now\"                                           │\n",
    "│         │                                                        │\n",
    "│         ▼                                                        │\n",
    "│  ┌─────────────────┐                                             │\n",
    "│  │   PostgreSQL    │◄── INSERT order                             │\n",
    "│  │                 │◄── UPDATE inventory                         │\n",
    "│  │  Orders Table   │◄── UPDATE customer loyalty points           │\n",
    "│  │  Products Table │                                             │\n",
    "│  │  Users Table    │    All in ONE transaction (ACID)            │\n",
    "│  └─────────────────┘                                             │\n",
    "│                                                                  │\n",
    "│  Characteristics:                                                │\n",
    "│  ✓ ACID transactions (Atomicity, Consistency, Isolation, Durable)│\n",
    "│  ✓ Low latency (milliseconds)                                    │\n",
    "│  ✓ High concurrency                                              │\n",
    "│  ✓ Row-based storage                                             │\n",
    "│  ✓ Strong consistency                                            │\n",
    "│  ✗ Not optimized for heavy analytics                             │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Relational Database Comparison:**\n",
    "| Database | Type | Best For | Key Features |\n",
    "|----------|------|----------|--------------|\n",
    "| **PostgreSQL** | Open Source | General purpose | JSON, extensions, advanced SQL |\n",
    "| **MySQL** | Open Source | Web apps | Replication, widely adopted |\n",
    "| **MariaDB** | Open Source | MySQL fork | Enhanced performance |\n",
    "| **Oracle** | Commercial | Enterprise | Advanced features, RAC |\n",
    "| **SQL Server** | Commercial | Microsoft shops | BI integration, .NET |\n",
    "| **Amazon Aurora** | Cloud | High performance | 5x MySQL, auto-scaling |\n",
    "| **Google Cloud SQL** | Cloud | Managed MySQL/PostgreSQL | GCP integration |\n",
    "| **Azure SQL** | Cloud | Microsoft cloud | Hyperscale, serverless |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Storage\n",
    "> in another note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Pattern: Row vs Column based \n",
    "\n",
    "This describes HOW data is physically stored on disk. It's a database architecture choice.  \n",
    "\n",
    "```text\n",
    "Original Table:\n",
    "┌────────┬─────────┬─────────┬───────────┐\n",
    "│ UserID │ OrderID │ Product │ Timestamp │\n",
    "├────────┼─────────┼─────────┼───────────┤\n",
    "│   A    │ order1  │  phone  │   time1   │\n",
    "│   B    │ order2  │  ipad   │   time2   │\n",
    "│   C    │ order3  │  laptop │   time3   │\n",
    "└────────┴─────────┴─────────┴───────────┘\n",
    "\n",
    "ROW-BASED STORAGE:                    COLUMN-BASED STORAGE:\n",
    "┌─────────────────────────────┐       ┌──────────────────┐\n",
    "│ A, order1, phone, time1     │       │ UserID: A, B, C  │\n",
    "│ B, order2, ipad, time2      │       │ OrderID: o1,o2,o3│\n",
    "│ C, order3, laptop, time3    │       │ Product: ph,ip,la│\n",
    "└─────────────────────────────┘       │ Time: t1, t2, t3 │\n",
    "                                      └──────────────────┘\n",
    "Records stored together               Columns stored together\n",
    "\n",
    "Good for:                              Good for:              \n",
    "• Get entire row                       • Aggregate columns    \n",
    "• Insert/Update row                    • Scan specific cols   \n",
    "• OLTP workloads                       • OLAP workloads       \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row-Based Storage (e.g., CSV, Traditional RDBMS)\n",
    "\n",
    "**How it works**: Data is stored row by row, with all columns of a record stored together.\n",
    "\n",
    "**Characteristics**:\n",
    "- Read or write entire rows at once\n",
    "- Efficient for accessing complete records\n",
    "- Best for **OLTP** (Online Transaction Processing)\n",
    "\n",
    "**Use Cases**:\n",
    "- E-commerce order processing\n",
    "- Banking transactions\n",
    "- User profile updates\n",
    "- Any operation that needs entire records\n",
    "\n",
    "\n",
    "## Column-Based Storage (e.g., Parquet, ORC)\n",
    "\n",
    "**How it works**: Data is stored column by column, with all values of a single column stored together.\n",
    "\n",
    "**Characteristics**:\n",
    "- Read only the columns you need\n",
    "- Excellent compression (similar values grouped together)\n",
    "- Best for **OLAP** (Online Analytical Processing) and Big Data\n",
    "\n",
    "**Use Cases**:\n",
    "- Data warehousing\n",
    "- Business intelligence dashboards\n",
    "- Aggregation queries\n",
    "- Big data analytics\n",
    "\n",
    "\n",
    "## Common File Formats\n",
    "\n",
    "| Format | Type | Characteristics |\n",
    "|--------|------|-----------------|\n",
    "| CSV | Row-based | Human-readable, no schema, poor compression |\n",
    "| JSON | Row-based | Flexible schema, human-readable |\n",
    "| Avro | Row-based | Schema evolution, compact binary |\n",
    "| Parquet | Column-based | Excellent compression, schema support |\n",
    "| ORC | Column-based | Optimized for Hive, ACID support |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "| Aspect | Row-Based | Column-Based |\n",
    "|--------|-----------|--------------|\n",
    "| **Data Layout** | Entire row stored contiguously | Each column stored separately |\n",
    "| **Write Performance** | Fast (one write per record) | Slower (multiple writes) |\n",
    "| **Read All Columns** | Efficient | Must reassemble rows |\n",
    "| **Read Few Columns** | Must read entire row | Very efficient |\n",
    "| **Compression** | Poor (mixed data types) | Excellent (same data type) |\n",
    "| **Best For** | OLTP, transactions | OLAP, analytics |\n",
    "| **Examples** | MySQL, PostgreSQL | Parquet, ORC, Redshift |\n",
    "\n",
    "\n",
    "```text\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                     QUERY PERFORMANCE Comparison                        │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│   Query: SELECT * FROM users WHERE id = 1                               │\n",
    "│   ═══════════════════════════════════════════                           │\n",
    "│                                                                         │\n",
    "│   ROW-BASED: ████ Fast! Read one row block                              │\n",
    "│   COLUMN:    ████████████ Slow! Read all column files                   │\n",
    "│                                                                         │\n",
    "│                                                                         │\n",
    "│   Query: SELECT SUM(amount) FROM users                                  │\n",
    "│   ═══════════════════════════════════════════                           │\n",
    "│                                                                         │\n",
    "│   ROW-BASED: ████████████ Slow! Read every row, discard other columns   │\n",
    "│   COLUMN:    ████ Fast! Read only amount column                         │\n",
    "│                                                                         │\n",
    "│                                                                         │\n",
    "│   Query: SELECT country, AVG(amount) FROM users GROUP BY country        │\n",
    "│   ═══════════════════════════════════════════════════════════════       │\n",
    "│                                                                         │\n",
    "│   ROW-BASED: ████████████ Slow! Full table scan                         │\n",
    "│   COLUMN:    ████ Fast! Read only 2 columns + great compression         │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "\n",
    "## Why Columnar Storage Excels for Analytics\n",
    "\n",
    "```sql\n",
    "-- Query: Calculate total sales by region\n",
    "SELECT region, SUM(sales_amount) \n",
    "FROM orders \n",
    "GROUP BY region;\n",
    "```\n",
    "\n",
    "**Row-Based Storage Cons:**\n",
    "```text\n",
    "Must read: [order_id, customer_id, product, region, sales_amount, date, ...]\n",
    "           ↑ Reading unnecessary columns wastes I/O\n",
    "```\n",
    "\n",
    "**Columnar Storage Pros:**\n",
    "```text\n",
    "Only reads: [region] + [sales_amount]\n",
    "           ↑ Reads only what's needed = 80% less I/O\n",
    "```\n",
    "\n",
    "### Compression Benefits\n",
    "\n",
    "```text\n",
    "Column: Product Category\n",
    "┌─────────────────────────────────────────┐\n",
    "│ Electronics, Electronics, Electronics,  │\n",
    "│ Electronics, Clothing, Clothing,        │\n",
    "│ Clothing, Clothing, Clothing, ...       │\n",
    "└─────────────────────────────────────────┘\n",
    "           ↓ Run-length encoding\n",
    "┌─────────────────────────────────────────┐\n",
    "│ Electronics (4x), Clothing (5x), ...    │\n",
    "└─────────────────────────────────────────┘\n",
    "           ↑ 10:1 compression ratio possible\n",
    "```\n",
    "\n",
    "## Example Systems\n",
    "\n",
    "```text\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│   ┌─────────────────────────────────────────────────────────────────┐   │\n",
    "│   │                                                                 │   │\n",
    "│   │   TRADITIONAL DATABASES                                         │   │\n",
    "│   │   ═════════════════════                                         │   │\n",
    "│   │                                                                 │   │\n",
    "│   │   Row-Based:                    Column-Based:                   │   │\n",
    "│   │   • Oracle (default)            • Sybase IQ (1996)              │   │\n",
    "│   │   • SQL Server (default)        • Vertica (2005)                │   │\n",
    "│   │   • PostgreSQL (default)        • SQL Server (columnstore idx)  │   │\n",
    "│   │   • MySQL                       • Oracle (in-memory columnar)   │   │\n",
    "│   │   • IBM DB2                     • Teradata (hybrid)             │   │\n",
    "│   │                                                                 │   │\n",
    "│   └─────────────────────────────────────────────────────────────────┘   │\n",
    "│                                                                         │\n",
    "│   ┌─────────────────────────────────────────────────────────────────┐   │\n",
    "│   │                                                                 │   │\n",
    "│   │   BIG DATA                                                      │   │\n",
    "│   │   ════════                                                      │   │\n",
    "│   │                                                                 │   │\n",
    "│   │   Row-Based:                    Column-Based:                   │   │\n",
    "│   │   • Cassandra                   • Snowflake                     │   │\n",
    "│   │   • HBase                       • BigQuery                      │   │\n",
    "│   │   • MongoDB                     • Redshift                      │   │\n",
    "│   │   • DynamoDB                    • ClickHouse                    │   │\n",
    "│   │   • CSV, JSON, Avro (files)     • Parquet, ORC (files)          │   │\n",
    "│   │                                                                 │   │\n",
    "│   └─────────────────────────────────────────────────────────────────┘   │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLTP vs OLAP\n",
    "\n",
    "OLTP and OLAP describe WORKLOAD PATTERNS, not specific technologies\n",
    "\n",
    "\n",
    "```text\n",
    " ┌─────────────────────────────────┬────────────────────────────────┐\n",
    " │             OLTP                │             OLAP               │\n",
    " │   (Online Transaction Process)  │  (Online Analytical Process)   │\n",
    " ├─────────────────────────────────┼────────────────────────────────┤\n",
    " │                                 │                                │\n",
    " │   WHAT: Run the business        │   WHAT: Analyze the business   │\n",
    " │                                 │                                │\n",
    " │   • Insert order                │   • Sum of sales by region     │\n",
    " │   • Update inventory            │   • Average order value        │\n",
    " │   • Read user profile           │   • Year-over-year growth      │\n",
    " │                                 │                                │\n",
    " │   HOW:                          │   HOW:                         │\n",
    " │   • Many small transactions     │   • Few large scans            │\n",
    " │   • Row-based access            │   • Column-based access        │\n",
    " │   • Current state               │   • Historical data            │\n",
    " │   • Milliseconds latency        │   • Seconds/minutes latency    │\n",
    " │                                 │                                │\n",
    " │   \"What happened just now?\"     │    \"What patterns exist?\"      │\n",
    " │                                 │                                │\n",
    " │   ┌─────┐ INSERT                │    ┌───────────────────────┐   │\n",
    " │   │User │─────▶ ┌────┐          │    │ SELECT SUM(sales)     │   │\n",
    " │   └─────┘       │ DB │          │    │ FROM orders           │   │\n",
    " │   ┌─────┐ UPDATE│    │          │    │ WHERE year = 2024     │   │\n",
    " │   │User │─────▶ │    │          │    │ GROUP BY region       │   │\n",
    " │   └─────┘       └────┘          │    └───────────────────────┘   │\n",
    " │                                 │             │                  │\n",
    " │   Many small transactions       │     Few complex queries        │\n",
    " │                                 │                                │\n",
    " └─────────────────────────────────┴────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Comparison\n",
    "\n",
    "| Characteristic | OLTP | OLAP |\n",
    "|----------------|------|------|\n",
    "| **Primary Purpose** | Day-to-day operations | Business intelligence & analytics |\n",
    "| **Operations** | INSERT, UPDATE, DELETE | SELECT with aggregations |\n",
    "| **Query Complexity** | Simple, short | Complex, long-running |\n",
    "| **Data Freshness** | Current, real-time | Historical, periodic refresh |\n",
    "| **Concurrency** | Thousands of users | Dozens of analysts |\n",
    "| **Response Time** | Milliseconds | Seconds to minutes |\n",
    "| **Data Volume per Query** | Few records | Millions of records |\n",
    "| **Storage Orientation** | commonly Row-based | optimizedly Column-based |\n",
    "| **Normalization** | Highly normalized (3NF) | Denormalized (Star/Snowflake) |\n",
    "\n",
    "## Example Systems\n",
    "\n",
    "```text\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                                                                         │\n",
    "│                           OLTP                        OLAP              │\n",
    "│                      (Transactions)               (Analytics)           │\n",
    "│                            │                           │                │\n",
    "│   ┌────────────────────────┴───────────────────────────┴──────────────┐ │\n",
    "│   │                                                                   │ │\n",
    "│   │   TRADITIONAL DATABASES (Pre-Big Data Era)                        │ │\n",
    "│   │   ════════════════════════════════════════                        │ │\n",
    "│   │                                                                   │ │\n",
    "│   │   OLTP:                          OLAP:                            │ │\n",
    "│   │   • Oracle (transactions)        • Oracle (with analytics)        │ │\n",
    "│   │   • SQL Server (transactions)    • SQL Server Analysis Services   │ │\n",
    "│   │   • PostgreSQL                   • Teradata (1984!)               │ │\n",
    "│   │   • MySQL                        • Netezza                        │ │\n",
    "│   │                                                                   │ │\n",
    "│   │   These existed since 1980s-90s!                                  │ │\n",
    "│   │                                                                   │ │\n",
    "│   └───────────────────────────────────────────────────────────────────┘ │\n",
    "│                                                                         │\n",
    "│   ┌───────────────────────────────────────────────────────────────────┐ │\n",
    "│   │                                                                   │ │\n",
    "│   │   BIG DATA ERA (2000s+)                                           │ │\n",
    "│   │   ═════════════════════                                           │ │\n",
    "│   │                                                                   │ │\n",
    "│   │   OLTP (at scale):               OLAP (at scale):                 │ │\n",
    "│   │   • Cassandra                    • Snowflake                      │ │\n",
    "│   │   • DynamoDB                     • BigQuery                       │ │\n",
    "│   │   • HBase                        • Redshift                       │ │\n",
    "│   │   • MongoDB (can scale)          • ClickHouse                     │ │\n",
    "│   │                                  • Spark SQL                      │ │\n",
    "│   │                                  • Data Lake + Query Engine       │ │\n",
    "│   │                                                                   │ │\n",
    "│   └───────────────────────────────────────────────────────────────────┘ │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "History   \n",
    "```text\n",
    "1970s    OLTP concept born (IBM, Oracle)                             \n",
    "   │     └── Relational databases for transactions                   \n",
    "   │                                                                  \n",
    "1980s    OLAP concept coined                                         \n",
    "   │     └── Data warehousing begins (Teradata 1984)                 \n",
    "   │                                                                  \n",
    "1990s    Traditional Data Warehouses                                 \n",
    "   │     └── Oracle, SQL Server, Teradata, Netezza                   \n",
    "   │     └── Star Schema, OLAP Cubes                                 \n",
    "   │                                                                  \n",
    "2000s    Big Data Era begins                                         \n",
    "   │     └── Hadoop, HDFS, MapReduce (2006)                         \n",
    "   │     └── NoSQL movement                                          \n",
    "   │                                                                \n",
    "2010s    Cloud Data Warehouses                                       \n",
    "   │     └── Redshift (2012), BigQuery (2011), Snowflake (2014)     \n",
    "   │     └── Same OLAP concept, but at massive scale                \n",
    "   │                                                                  \n",
    "2020s    Lakehouse + Real-time                                       \n",
    "         └── Delta Lake, Iceberg                                     \n",
    "         └── Streaming analytics                                     \n",
    "                                                                    \n",
    "OLTP/OLAP concepts stayed the same - only SCALE changed!\n",
    "```\n",
    "\n",
    "## Real-World Example\n",
    "\n",
    "```text\n",
    "E-Commerce Company:\n",
    "\n",
    "OLTP Database (PostgreSQL):\n",
    "├── Handles 10,000 orders/second\n",
    "├── User adds item to cart → INSERT\n",
    "├── User updates address → UPDATE\n",
    "├── User completes purchase → Transaction\n",
    "└── Response time: 5ms\n",
    "\n",
    "OLAP Database (Redshift):\n",
    "├── Refreshed nightly from OLTP\n",
    "├── \"Top 10 products by revenue last quarter\"\n",
    "├── \"Customer churn rate by acquisition channel\"\n",
    "├── Scans 500M rows\n",
    "└── Response time: 30 seconds\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Common Pairing of OLTP/OLAP & ROW/COLUMN\n",
    "\n",
    "```text\n",
    "\n",
    "┌───────────────────────────────────────────────────────────────┐\n",
    "│                        STORAGE FORMAT                         │\n",
    "│                                                               │\n",
    "│                    Row-Based    Column-Based                  │\n",
    "│                        │             │                        │\n",
    "│   W  ┌─────────────────┼─────────────┼─────────────────┐      │\n",
    "│   O  │                 │             │                 │      │\n",
    "│   R  │   OLTP     ███████████        │░░░░░            │      │\n",
    "│   K  │            (Common)           │(Rare)           │      │\n",
    "│   L  │                 │             │                 │      │\n",
    "│   O  ├─────────────────┼─────────────┼─────────────────┤      │\n",
    "│   A  │                 │             │                 │      │\n",
    "│   D  │   OLAP          │░░░░░   ███████████            │      │\n",
    "│      │                 │(Rare)       │(Common)         │      │\n",
    "│      │                 │             │                 │      │\n",
    "│      └─────────────────┴─────────────┴─────────────────┘      │\n",
    "│                                                               │\n",
    "│   ███ = Common pairing (optimized for that workload)          │\n",
    "│   ░░░ = Possible but not optimal                              │\n",
    "│                                                               │\n",
    "└───────────────────────────────────────────────────────────────┘\n",
    "\n",
    "```\n",
    "\n",
    "| Database | Workload | Storage | Notes |\n",
    "|----------|----------|---------|-------|\n",
    "| **PostgreSQL** | OLTP | Row | Classic pairing |\n",
    "| **MySQL** | OLTP | Row | Classic pairing |\n",
    "| **MongoDB** | OLTP | Document (Row-like) | Classic pairing |\n",
    "| **Snowflake** | OLAP | Column | Classic pairing |\n",
    "| **BigQuery** | OLAP | Column | Classic pairing |\n",
    "| **ClickHouse** | OLAP | Column | Classic pairing |\n",
    "| **SAP HANA** | Both | Column | Exception! Columnar but fast OLTP |\n",
    "| **SQL Server** | Both | Both | Has columnstore indexes for OLAP |\n",
    "| **PostgreSQL** | OLAP (small) | Row | Works but not optimal |\n",
    "| **Cassandra** | OLTP (writes) | Row (wide-column) | Optimized for writes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Dimensional Modeling](./reading/Dimensional%20modeling_Data_Warehouse.pdf): Star vs Snowflake Schema\n",
    "\n",
    "## Overview\n",
    "Star/Snowflake Schema are Data modeling patterns, are specific structural implementations of dimensional modeling.\n",
    "\n",
    "<img src=\"./pic/1_star_snowflake_schema.webp\" width=600>\n",
    "\n",
    "**Star Schema:**   \n",
    "\n",
    "The simplest dimensional model where the fact table sits at the center connected directly to denormalized dimension tables.    \n",
    " \n",
    "```text\n",
    "                    ┌─────────────┐\n",
    "                    │    Time     │\n",
    "                    │ Dimension   │\n",
    "                    │─────────────│\n",
    "                    │ time_id     │\n",
    "                    │ date        │\n",
    "                    │ day_of_week │\n",
    "                    │ month       │\n",
    "                    │ quarter     │\n",
    "                    │ year        │\n",
    "                    └──────┬──────┘\n",
    "                           │\n",
    "┌─────────────┐    ┌──────┴──────┐    ┌─────────────┐\n",
    "│   Product   │    │             │    │  Location   │\n",
    "│ Dimension   │────│    FACT     │────│ Dimension   │\n",
    "│─────────────│    │   SALES     │    │─────────────│\n",
    "│ product_id  │    │─────────────│    │ location_id │\n",
    "│ name        │    │ amount      │    │ city        │\n",
    "│ category    │    │ quantity    │    │ state       │\n",
    "│ subcategory │    │ product_id  │    │ country     │\n",
    "│ brand       │    │ customer_id │    │ region      │\n",
    "└─────────────┘    │ location_id │    └─────────────┘\n",
    "                   │ time_id     │\n",
    "┌─────────────┐    └──────┬──────┘\n",
    "│  Customer   │           │\n",
    "│ Dimension   │───────────┘\n",
    "│─────────────│\n",
    "│ customer_id │\n",
    "│ name        │\n",
    "│ email       │\n",
    "│ segment     │\n",
    "│ tier        │\n",
    "└─────────────┘\n",
    "```\n",
    "\n",
    "**Snowflake Schema (Normalized):**   \n",
    "\n",
    "Normalized version where dimension tables are split into sub-dimensions.\n",
    "\n",
    "```text\n",
    "┌─────────┐    ┌─────────────┐\n",
    "│Category │────│   Product   │\n",
    "│─────────│    │ Dimension   │\n",
    "│cat_id   │    │─────────────│\n",
    "│name     │    │ product_id  │\n",
    "└─────────┘    │ name        │──┐\n",
    "               │ category_id │  │\n",
    "┌─────────┐    │ brand_id    │  │\n",
    "│ Brand   │────└─────────────┘  │\n",
    "│─────────│                     │\n",
    "│brand_id │                     │\n",
    "│name     │          ┌──────────┴──────────┐\n",
    "└─────────┘          │      FACT SALES     │\n",
    "                     └─────────────────────┘\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Comparison\n",
    "\n",
    "| Aspect | Star Schema | Snowflake Schema |\n",
    "|--------|-------------|------------------|\n",
    "| **Structure** | Denormalized dimensions | Normalized dimensions |\n",
    "| **Joins** | Fewer (simpler queries) | More (complex queries) |\n",
    "| **Query Speed** | Faster | Slower |\n",
    "| **Storage** | Higher (redundancy) | Lower (no redundancy) |\n",
    "| **Maintenance** | Easier | More complex |\n",
    "| **ETL Complexity** | Simpler | More complex |\n",
    "| **Best For** | BI tools, dashboards | Large dimensions, storage-sensitive |\n",
    "\n",
    "## When to Use Each\n",
    "\n",
    "**Star Schema (Recommended Default):**\n",
    "- Simple, fast queries are priority\n",
    "- Business users write their own queries\n",
    "- Dimension tables are reasonably sized\n",
    "- Using BI tools like Tableau, Power BI\n",
    "\n",
    "**Snowflake Schema:**\n",
    "- Storage cost is critical concern\n",
    "- Dimensions have millions of rows\n",
    "- Need to avoid update anomalies\n",
    "- Data integrity is paramount\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow Change Dimension (SCD)\n",
    "SCD Type 0 — No Change (Keep Original Value)\n",
    "● Original value is never changed\n",
    "● No updates, no history tracking\n",
    "● Data is treated as static\n",
    "SCD Type 1 — Overwrite (No History)\n",
    "● Attribute is updated in place\n",
    "● Old value is lost\n",
    "● Table always reflects latest state only\n",
    "SCD Type 2 — Full History Tracking\n",
    "● Do not overwrite old records\n",
    "● Insert a new row when data changes\n",
    "● Maintain multiple records per business key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema-on-Write vs Schema-on-Read\n",
    "\n",
    "| Approach | When Schema Applied | Flexibility | Query Speed |\n",
    "|----------|---------------------|-------------|-------------|\n",
    "| **Schema-on-Write** (Traditional DB) | Before loading data | Low | Fast |\n",
    "| **Schema-on-Read** (Data Lake) | When querying data | High | Slower |\n",
    "\n",
    "\n",
    "## Schema-on-Write\n",
    "\n",
    "**Definition**:    \n",
    "\n",
    "In a schema-on-write system, the data schema is defined before data is ingested. Incoming data must conform to this predefined structure.\n",
    "\n",
    "**How it works**:     \n",
    "- Schema is enforced at ingestion time\n",
    "- Data that doesn’t match the schema is rejected or must be transformed\n",
    "- Common in traditional relational databases and data warehouses\n",
    "\n",
    "**Pros**:      \n",
    "- Strong data consistency and quality\n",
    "- Easier querying and optimization\n",
    "- Predictable structure for BI and reporting\n",
    "- Better for regulated or mission-critical data\n",
    "\n",
    "**Cons**:\n",
    "- Less flexible when data formats change\n",
    "- Slower ingestion due to validation and transformation\n",
    "- Requires upfront schema design\n",
    "\n",
    "**Typical technologies**:\n",
    "- **Relational databases** (PostgreSQL, MySQL, Oracle)\n",
    "- **Traditional data warehouses** (Redshift, Snowflake, BigQuery)\n",
    "\n",
    "**Use cases**:\n",
    "- Financial reporting\n",
    "- Structured transactional systems\n",
    "- Dashboards with well-defined metrics\n",
    "\n",
    "\n",
    "\n",
    "## Schema-on-Read  \n",
    "\n",
    "**Definition**:   \n",
    "\n",
    "In a schema-on-read system, **data is stored in its raw form**, and the schema is applied when the data is read or queried.\n",
    "\n",
    "**How it works**:\n",
    "- No strict schema at ingestion time\n",
    "- Schema is interpreted dynamically at query time\n",
    "- Common in data lakes and big data systems\n",
    "\n",
    "**Pros**:    \n",
    "- High flexibility for evolving data\n",
    "- Fast ingestion of diverse data sources\n",
    "- Supports semi-structured and unstructured data\n",
    "- Ideal for exploratory analytics and ML\n",
    "\n",
    "**Cons**:\n",
    "- Query complexity is higher\n",
    "- Data quality issues may surface late\n",
    "- Slower queries due to on-the-fly parsing\n",
    "\n",
    "**Typical technologies**:\n",
    "- **Data lakes** (S3, ADLS, GCS)\n",
    "- **Big data tools** (Spark, Hive, Presto, Athena)\n",
    "- File formats like JSON, Parquet, Avro\n",
    "\n",
    "**Use cases**:\n",
    "- Log and event data\n",
    "- Data science and experimentation\n",
    "- Rapidly changing data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medallion Architecture (Bronze / Silver / Gold Layers)\n",
    "\n",
    "Medallion Architecture (also called Multi-Hop Architecture) is a **data organization pattern** that organizes data into three progressive layers. It can be applied across various storage systems, it isn't exclusive to data lakes.  \n",
    "\n",
    "<img src=\"./pic/0_bronze_silver_gold.png\" width=600>\n",
    "\n",
    "**Where it's commonly used**:\n",
    "\n",
    "- Data lakehouses (Databricks popularized the term here)\n",
    "- Data warehouses (Snowflake, BigQuery, Redshift)\n",
    "- Traditional data lakes (S3, ADLS, GCS with Delta/Iceberg/Hudi)\n",
    "- Hybrid architectures mixing lakes and warehouses\n",
    "\n",
    "The **core concept** is really about **data quality progression**:    \n",
    "\n",
    "- **Bronze**: Raw, unprocessed data as ingested (schema-on-read, minimal transformation)\n",
    "- **Silver**: Cleaned, deduplicated, validated data (conforming to business rules)\n",
    "- **Gold**: Aggregated, business-ready data (optimized for analytics/reporting)\n",
    "\n",
    "This layered approach to data refinement works regardless of where the data physically lives. You could implement it in a purely warehouse-based architecture using different schemas or databases to represent each layer.   \n",
    "\n",
    "The reason it's **so associated with data lakes** is that lakes historically lacked the structure and governance of warehouses, so the medallion pattern provided a much-needed organizational framework. But conceptually, it's just a staging pattern for progressive data quality—applicable anywhere you're doing ETL/ELT pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze Layer — Raw Data\n",
    "\n",
    "**Purpose**: Landing zone for raw data ingestion\n",
    "\n",
    "**Characteristics**:\n",
    "\n",
    "| Aspect | Description |\n",
    "|--------|-------------|\n",
    "| Transformation | Minimal or none |\n",
    "| Schema | May be inconsistent |\n",
    "| Data Quality | Unvalidated |\n",
    "| Write Pattern | Append-only |\n",
    "| Primary Use | Replay, debugging, audit trail |\n",
    "\n",
    "**What goes into Bronze**:\n",
    "- Raw JSON/CSV files as-is\n",
    "- API responses without modification\n",
    "- Streaming data in original format\n",
    "- Database CDC (Change Data Capture) logs\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Bronze layer ingestion - minimal processing\n",
    "bronze_df = spark.read.json(\"s3://raw-data/events/\")\n",
    "bronze_df.write.format(\"delta\").mode(\"append\").save(\"s3://bronze/events/\")\n",
    "\n",
    "# Typical bronze table structure\n",
    "# ├── _raw_data (original payload)\n",
    "# ├── _ingestion_timestamp\n",
    "# ├── _source_system\n",
    "# └── _batch_id\n",
    "```\n",
    "\n",
    "## Silver Layer — Clean & Conformed Data\n",
    "\n",
    "**Purpose**: Validated, standardized data ready for analysis\n",
    "\n",
    "**Characteristics**:\n",
    "\n",
    "| Aspect | Description |\n",
    "|--------|-------------|\n",
    "| Data Quality | Cleaned and validated |\n",
    "| Duplicates | Removed (deduplicated) |\n",
    "| Schema | Standardized and enforced |\n",
    "| Business Rules | Applied |\n",
    "| Format | Common schema across sources |\n",
    "\n",
    "**Transformations Applied**:\n",
    "- Data type casting\n",
    "- Null handling\n",
    "- Deduplication\n",
    "- Schema enforcement\n",
    "- Data validation\n",
    "- Standardization (dates, currencies, etc.)\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Silver layer transformation\n",
    "silver_df = (\n",
    "    bronze_df\n",
    "    .dropDuplicates([\"event_id\"])\n",
    "    .filter(col(\"event_type\").isNotNull())\n",
    "    .withColumn(\"event_date\", to_date(\"timestamp\"))\n",
    "    .withColumn(\"amount\", col(\"amount\").cast(\"decimal(10,2)\"))\n",
    "    .select(\n",
    "        \"event_id\",\n",
    "        \"user_id\", \n",
    "        \"event_type\",\n",
    "        \"event_date\",\n",
    "        \"amount\"\n",
    "    )\n",
    ")\n",
    "silver_df.write.format(\"delta\").mode(\"merge\").save(\"s3://silver/events/\")\n",
    "```\n",
    "\n",
    "## Gold Layer — Business-Level Aggregations\n",
    "\n",
    "**Purpose**: Business-ready data optimized for consumption\n",
    "\n",
    "**Characteristics**:\n",
    "\n",
    "| Aspect | Description |\n",
    "|--------|-------------|\n",
    "| Granularity | Aggregated |\n",
    "| Optimization | Query-optimized |\n",
    "| Purpose | Powers reports, dashboards, ML |\n",
    "| Structure | Dimensional models (star/snowflake) |\n",
    "| Users | Business analysts, data scientists |\n",
    "\n",
    "**Common Gold Layer Patterns**:\n",
    "- Fact tables (transactions, events)\n",
    "- Dimension tables (customers, products, time)\n",
    "- Pre-computed aggregations\n",
    "- Feature stores for ML\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Gold layer aggregation\n",
    "gold_daily_sales = (\n",
    "    silver_df\n",
    "    .groupBy(\"event_date\", \"product_category\")\n",
    "    .agg(\n",
    "        count(\"event_id\").alias(\"total_transactions\"),\n",
    "        sum(\"amount\").alias(\"total_revenue\"),\n",
    "        avg(\"amount\").alias(\"avg_transaction_value\"),\n",
    "        countDistinct(\"user_id\").alias(\"unique_customers\")\n",
    "    )\n",
    ")\n",
    "gold_daily_sales.write.format(\"delta\").mode(\"overwrite\").save(\"s3://gold/daily_sales/\")\n",
    "```\n",
    "\n",
    "## Layer Comparison Summary\n",
    "\n",
    "| Aspect | Bronze | Silver | Gold |\n",
    "|--------|--------|--------|------|\n",
    "| Data State | Raw | Cleaned | Aggregated |\n",
    "| Schema | Flexible | Enforced | Optimized |\n",
    "| Quality | Unvalidated | Validated | Business-ready |\n",
    "| Users | Engineers | Analysts/Engineers | Business/Analysts |\n",
    "| Updates | Append | Upsert/Merge | Overwrite/Append |\n",
    "| Retention | Long-term | Medium-term | Query-optimized |\n",
    "\n",
    "## Benefits of Medallion Architecture\n",
    "\n",
    "1. **Data Lineage**: Clear progression from raw to refined\n",
    "2. **Replayability**: Bronze layer allows reprocessing\n",
    "3. **Quality Control**: Progressive validation at each layer\n",
    "4. **Flexibility**: Different layers serve different needs\n",
    "5. **Debugging**: Easy to trace issues back to source\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Data Organization Patterns\n",
    "\n",
    "- Data Vault = how you model your tables\n",
    "- Medallion = how you stage your data through quality layers\n",
    "- Lambda/Kappa = how you process data (batch vs stream)\n",
    "- Data Mesh = how your organization manages data ownership\n",
    "\n",
    "## Data Vault\n",
    "## Data Mesh\n",
    "## Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Transactions\n",
    "\n",
    "A **transaction** is a **logical unit of work** that consists of **one or more database operations**. It represents a sequence of operations that must be executed as a single, indivisible unit.\n",
    "\n",
    "## Key Characteristics\n",
    "\n",
    "- **Unit of Work**: Groups multiple operations into one logical operation\n",
    "- **Multiple Operations**: Can include INSERT, UPDATE, DELETE, and SELECT statements\n",
    "- **Read and/or Modify**: Operations can retrieve data, change data, or both\n",
    "- **Atomic Execution**: Either ALL operations succeed, or NONE take effect\n",
    "- **All-or-Nothing**: If any operation fails, the entire transaction is rolled back\n",
    "\n",
    "## Transaction Syntax Example\n",
    "\n",
    "```sql\n",
    "-- Begin the transaction\n",
    "BEGIN TRAN;\n",
    "\n",
    "-- First operation: Insert into table T1\n",
    "INSERT INTO dbo.T1(keycol, col1, col2) VALUES (4, 101, 'C');\n",
    "\n",
    "-- Second operation: Insert into table T2\n",
    "INSERT INTO dbo.T2(keycol, col1, col2) VALUES (4, 201, 'X');\n",
    "\n",
    "-- Commit the transaction (make changes permanent)\n",
    "COMMIT TRAN;\n",
    "```\n",
    "\n",
    "### Transaction Control Statements\n",
    "\n",
    "| Statement | Description |\n",
    "|-----------|-------------|\n",
    "| `BEGIN TRAN` | Starts a new transaction |\n",
    "| `COMMIT TRAN` | Saves all changes made during the transaction |\n",
    "| `ROLLBACK TRAN` | Undoes all changes made during the transaction |\n",
    "| `SAVEPOINT` | Creates a point within a transaction to rollback to |\n",
    "\n",
    "### Real-World Example: Bank Transfer\n",
    "\n",
    "```sql\n",
    "BEGIN TRAN;\n",
    "\n",
    "-- Deduct $500 from Account A\n",
    "UPDATE Accounts SET balance = balance - 500 WHERE account_id = 'A';\n",
    "\n",
    "-- Add $500 to Account B\n",
    "UPDATE Accounts SET balance = balance + 500 WHERE account_id = 'B';\n",
    "\n",
    "-- If both succeed, commit\n",
    "COMMIT TRAN;\n",
    "\n",
    "-- If either fails, the entire transaction rolls back\n",
    "-- ensuring money isn't lost or created\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACID Properties\n",
    "> talked in session 07-database-advanced\n",
    "\n",
    "ACID is an acronym representing four essential properties that guarantee reliable database transactions.\n",
    "\n",
    "## A - Atomicity\n",
    "\n",
    "**Definition**: Each statement in a transaction is treated as a single unit. Either the entire statement executes completely, or none of it executes.\n",
    "\n",
    "**Purpose**: Prevents data loss and corruption\n",
    "\n",
    "**Example Scenario**:\n",
    "- A streaming data source fails mid-stream\n",
    "- Without atomicity: Partial data could be written, causing inconsistency\n",
    "- With atomicity: Either all streaming data is written or none is\n",
    "\n",
    "```text\n",
    "Transaction: Insert 1000 records\n",
    "├── Record 1-500: Successfully inserted\n",
    "├── Record 501: FAILS (e.g., constraint violation)\n",
    "└── Result: ALL 500 records are rolled back → 0 records inserted\n",
    "```\n",
    "\n",
    "## C - Consistency\n",
    "\n",
    "**Definition**: Transactions only make changes to tables in predefined, predictable ways. Data integrity constraints are always maintained.\n",
    "\n",
    "**Purpose**: Ensures data corruption or errors don't compromise table integrity\n",
    "\n",
    "**Examples of Consistency Rules**:\n",
    "- Foreign key constraints must be satisfied\n",
    "- Check constraints must pass\n",
    "- Data types must be valid\n",
    "- Unique constraints must be maintained\n",
    "\n",
    "```sql\n",
    "-- Example: Consistency prevents this invalid state\n",
    "-- If orders.customer_id references customers.id:\n",
    "\n",
    "BEGIN TRAN;\n",
    "INSERT INTO orders (id, customer_id, amount) \n",
    "VALUES (1, 999, 100.00);  -- customer_id 999 doesn't exist\n",
    "COMMIT TRAN;\n",
    "-- Transaction FAILS due to foreign key constraint\n",
    "-- Consistency is maintained\n",
    "```\n",
    "\n",
    "## I - Isolation\n",
    "\n",
    "**Definition**: When multiple users read and write from the same table simultaneously, their transactions don't interfere with each other.\n",
    "\n",
    "**Purpose**: Ensures concurrent transactions appear to execute sequentially\n",
    "\n",
    "**Isolation Levels** (from lowest to highest):\n",
    "\n",
    "| Level | Dirty Read | Non-Repeatable Read | Phantom Read |\n",
    "|-------|------------|---------------------|--------------|\n",
    "| Read Uncommitted | ✓ Possible | ✓ Possible | ✓ Possible |\n",
    "| Read Committed | ✗ Prevented | ✓ Possible | ✓ Possible |\n",
    "| Repeatable Read | ✗ Prevented | ✗ Prevented | ✓ Possible |\n",
    "| Serializable | ✗ Prevented | ✗ Prevented | ✗ Prevented |\n",
    "\n",
    "**Concurrency Problems Explained**:\n",
    "\n",
    "```text\n",
    "DIRTY READ:\n",
    "Transaction A: UPDATE balance = 1000 (not committed)\n",
    "Transaction B: SELECT balance → reads 1000\n",
    "Transaction A: ROLLBACK\n",
    "Transaction B: Has incorrect data!\n",
    "\n",
    "NON-REPEATABLE READ:\n",
    "Transaction A: SELECT balance → 500\n",
    "Transaction B: UPDATE balance = 600, COMMIT\n",
    "Transaction A: SELECT balance → 600 (different value!)\n",
    "\n",
    "PHANTOM READ:\n",
    "Transaction A: SELECT COUNT(*) WHERE age > 25 → 10 rows\n",
    "Transaction B: INSERT new row with age = 30, COMMIT\n",
    "Transaction A: SELECT COUNT(*) WHERE age > 25 → 11 rows (new row appeared!)\n",
    "```\n",
    "\n",
    "## D - Durability\n",
    "\n",
    "**Definition**: Changes made by successfully executed transactions are permanently saved, even if the system fails immediately after.\n",
    "\n",
    "**Purpose**: Guarantees data persistence\n",
    "\n",
    "**Implementation Mechanisms**:\n",
    "- Write-Ahead Logging (WAL)\n",
    "- Transaction logs\n",
    "- Checkpoints\n",
    "- Redundant storage\n",
    "\n",
    "```text\n",
    "Timeline:\n",
    "1. Transaction commits at 10:00:00\n",
    "2. System confirms success to user\n",
    "3. Power failure at 10:00:01\n",
    "4. System restarts at 10:05:00\n",
    "5. Data from step 1 is STILL PRESENT (durability guarantee)\n",
    "```\n",
    "\n",
    "## ACID Summary Table\n",
    "\n",
    "| Property | Guarantees | Protects Against |\n",
    "|----------|------------|------------------|\n",
    "| Atomicity | All-or-nothing execution | Partial updates |\n",
    "| Consistency | Valid state transitions | Data corruption |\n",
    "| Isolation | Concurrent transaction independence | Race conditions |\n",
    "| Durability | Permanent commit | System failures |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
