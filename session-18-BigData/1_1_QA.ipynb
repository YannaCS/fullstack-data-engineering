{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data & Data Engineering Q&A\n",
    "\n",
    "### 1. Why can't traditional single-node databases (e.g., MySQL/PostgreSQL) handle Big Data workloads?\n",
    "\n",
    "Traditional single-node databases face several fundamental limitations when dealing with Big Data:\n",
    "\n",
    "**Vertical Scaling Limits**: Single-node databases can only scale up (adding more CPU, RAM, storage to one machine), which has physical and economic ceilings. You can't infinitely upgrade a single server.\n",
    "\n",
    "**Storage Capacity**: A single machine has finite disk space. Big Data workloads often involve petabytes of data that simply cannot fit on one node.\n",
    "\n",
    "**Processing Bottlenecks**: All queries must be processed by one CPU/memory system. Complex analytical queries on billions of rows would take hours or days, as there's no parallelism across machines.\n",
    "\n",
    "**I/O Constraints**: Disk read/write speeds become bottlenecks. Even with SSDs, reading terabytes of data through a single I/O channel is slow.\n",
    "\n",
    "**No Fault Tolerance**: If the single node fails, the entire database becomes unavailable. There's no built-in redundancy.\n",
    "\n",
    "**Concurrency Limits**: High-volume concurrent read/write operations overwhelm a single node's connection and lock management capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What problems do distributed systems solve, and what new challenges do they introduce?\n",
    "\n",
    "**Problems Solved:**\n",
    "- **Scalability**: Horizontal scaling by adding more nodes to handle growing data and traffic\n",
    "- **Fault Tolerance**: Data replication across nodes ensures availability even when machines fail\n",
    "- **Performance**: Parallel processing across multiple nodes dramatically speeds up computations\n",
    "- **Storage Capacity**: Combined storage across many machines can handle petabyte-scale data\n",
    "- **Geographic Distribution**: Data can be placed closer to users for lower latency\n",
    "\n",
    "**New Challenges Introduced:**\n",
    "- **Network Partitions**: Nodes may become unreachable, requiring decisions about consistency vs. availability (CAP theorem)\n",
    "- **Data Consistency**: Keeping data synchronized across nodes is complex; must choose between strong and eventual consistency\n",
    "- **Coordination Overhead**: Distributed transactions, leader election, and consensus protocols add complexity\n",
    "- **Debugging Difficulty**: Tracing issues across multiple nodes is significantly harder\n",
    "- **Data Skew**: Uneven data distribution can create hotspots and load imbalance\n",
    "- **Increased Latency**: Network communication between nodes adds overhead compared to local operations\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Compare OLTP and OLAP systems. What are their design goals?\n",
    "\n",
    "| Aspect | OLTP (Online Transaction Processing) | OLAP (Online Analytical Processing) |\n",
    "|--------|--------------------------------------|-------------------------------------|\n",
    "| **Purpose** | Handle day-to-day transactions | Support complex analytical queries |\n",
    "| **Operations** | INSERT, UPDATE, DELETE (many small ops) | SELECT with aggregations (few large reads) |\n",
    "| **Query Pattern** | Simple queries on few rows | Complex queries scanning millions of rows |\n",
    "| **Data Model** | Normalized (3NF) to minimize redundancy | Denormalized (star/snowflake schema) for read performance |\n",
    "| **Optimization** | Write-optimized, low latency | Read-optimized, high throughput |\n",
    "| **Concurrency** | High (thousands of concurrent users) | Lower (analysts running batch queries) |\n",
    "| **Data Freshness** | Real-time, current state | Historical, periodic updates |\n",
    "| **Examples** | Banking systems, e-commerce orders | Business intelligence, reporting dashboards |\n",
    "\n",
    "**Design Goals:**\n",
    "- **OLTP**: Maximize transaction throughput, ensure ACID compliance, minimize response time for individual operations\n",
    "- **OLAP**: Maximize query performance for aggregations, support ad-hoc analysis, handle large data volumes efficiently\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Describe the differences between ETL and ELT. Why is ELT more commonly used in cloud-based architectures such as AWS?\n",
    "\n",
    "**ETL (Extract, Transform, Load):**\n",
    "1. **Extract** data from source systems\n",
    "2. **Transform** data in a staging/processing server (clean, aggregate, join)\n",
    "3. **Load** transformed data into the destination warehouse\n",
    "\n",
    "**ELT (Extract, Load, Transform):**\n",
    "1. **Extract** data from source systems\n",
    "2. **Load** raw data directly into the destination (data lake/warehouse)\n",
    "3. **Transform** data within the destination system using its compute power\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "| Aspect | ETL | ELT |\n",
    "|--------|-----|-----|\n",
    "| Transform Location | External processing server | Inside the target system |\n",
    "| Data Movement | Only transformed data reaches warehouse | Raw data stored, transformed in place |\n",
    "| Flexibility | Schema defined upfront | Schema-on-read, more flexible |\n",
    "| Storage Cost | Lower (only processed data) | Higher (raw + processed data) |\n",
    "\n",
    "**Why ELT is preferred in cloud architectures:**\n",
    "\n",
    "1. **Elastic Compute**: Cloud warehouses (Redshift, Snowflake, BigQuery) offer massive parallel processing—cheaper to transform data there than maintain separate ETL servers\n",
    "\n",
    "2. **Separation of Storage and Compute**: Cloud platforms decouple these, making it economical to store raw data cheaply (S3) and spin up compute only when needed\n",
    "\n",
    "3. **Scalability**: Cloud systems auto-scale; no need to provision ETL infrastructure\n",
    "\n",
    "4. **Data Lake Pattern**: Raw data preservation enables future use cases without re-extraction\n",
    "\n",
    "5. **Cost Model**: Pay-per-query pricing makes it efficient to transform data on-demand rather than maintaining always-on ETL pipelines\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Explain the MapReduce execution flow in your own words. What are the roles of the Map, Shuffle, and Reduce phases?\n",
    "\n",
    "**MapReduce** is a programming model for processing large datasets in parallel across a distributed cluster.\n",
    "\n",
    "**Execution Flow:**\n",
    "\n",
    "```\n",
    "Input Data → Split → Map → Shuffle & Sort → Reduce → Output\n",
    "```\n",
    "\n",
    "**Phase Breakdown:**\n",
    "\n",
    "**1. Map Phase**\n",
    "- Input data is split into chunks distributed across worker nodes\n",
    "- Each mapper processes its chunk independently and in parallel\n",
    "- Mappers emit intermediate key-value pairs\n",
    "- *Example*: For word count, mapper reads \"hello world hello\" and emits: `(hello, 1), (world, 1), (hello, 1)`\n",
    "\n",
    "**2. Shuffle & Sort Phase**\n",
    "- The framework automatically groups all values by key\n",
    "- Data is transferred across the network so all values for the same key arrive at the same reducer\n",
    "- Values are sorted by key\n",
    "- *Example*: All `(hello, [1, 1])` pairs go to one reducer, `(world, [1])` to another\n",
    "\n",
    "**3. Reduce Phase**\n",
    "- Each reducer receives a key and all its associated values\n",
    "- Reducer applies aggregation logic (sum, count, average, etc.)\n",
    "- Outputs final results\n",
    "- *Example*: Reducer receives `(hello, [1, 1])` and outputs `(hello, 2)`\n",
    "\n",
    "**In essence**: Map handles parallel transformation, Shuffle handles data redistribution by key, and Reduce handles aggregation.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Explain the difference between Data Lake and Data Warehouse.\n",
    "\n",
    "| Aspect | Data Lake | Data Warehouse |\n",
    "|--------|-----------|----------------|\n",
    "| **Data Type** | Raw, unstructured, semi-structured, structured | Structured, processed, curated |\n",
    "| **Schema** | Schema-on-read (define when querying) | Schema-on-write (define before loading) |\n",
    "| **Storage Format** | Files (Parquet, JSON, CSV, images, logs) | Tables with strict schemas |\n",
    "| **Users** | Data scientists, ML engineers | Business analysts, BI users |\n",
    "| **Processing** | Flexible; batch and streaming | Primarily optimized for SQL queries |\n",
    "| **Cost** | Low (cheap object storage like S3) | Higher (optimized compute + storage) |\n",
    "| **Data Quality** | Variable; may contain duplicates/errors | High; cleaned and validated |\n",
    "| **Use Cases** | ML training, exploration, raw data archival | Reporting, dashboards, business metrics |\n",
    "| **Examples** | AWS S3 + Athena, Azure Data Lake | Snowflake, Redshift, BigQuery |\n",
    "\n",
    "**Key Insight**: Modern architectures often use both—data lakes for raw storage and flexibility, data warehouses for curated analytics. The **Lakehouse** pattern (Delta Lake, Iceberg) attempts to combine benefits of both.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. What is the difference between Batch Processing and Streaming Processing? Give one real-world use case for each.\n",
    "\n",
    "**Batch Processing:**\n",
    "- Processes large volumes of data at scheduled intervals\n",
    "- Data is collected over time, then processed together\n",
    "- Higher latency (minutes to hours)\n",
    "- Higher throughput for large datasets\n",
    "- Simpler to implement and debug\n",
    "\n",
    "**Streaming Processing:**\n",
    "- Processes data continuously as it arrives\n",
    "- Real-time or near-real-time results\n",
    "- Low latency (milliseconds to seconds)\n",
    "- More complex state management\n",
    "- Handles unbounded data streams\n",
    "\n",
    "| Aspect | Batch | Streaming |\n",
    "|--------|-------|-----------|\n",
    "| Latency | High (minutes-hours) | Low (ms-seconds) |\n",
    "| Data Scope | Bounded, finite datasets | Unbounded, continuous |\n",
    "| Complexity | Simpler | More complex |\n",
    "| Use Case Fit | Historical analysis | Real-time reactions |\n",
    "\n",
    "**Real-World Use Cases:**\n",
    "\n",
    "**Batch Processing Example: Monthly Financial Reports**\n",
    "- A bank collects all transactions throughout the month\n",
    "- At month-end, a batch job processes millions of records to generate statements, calculate interest, and produce regulatory reports\n",
    "- Results don't need to be instant; accuracy and completeness matter more\n",
    "\n",
    "**Streaming Processing Example: Fraud Detection**\n",
    "- A credit card company monitors transactions in real-time\n",
    "- Each swipe is analyzed instantly against patterns (unusual location, amount, frequency)\n",
    "- Suspicious transactions trigger immediate alerts or blocks\n",
    "- Waiting hours (batch) would be too late—the fraud would already have occurred\n",
    "\n",
    "---\n",
    "\n",
    "### 8. What is the purpose of Star Schema and Snowflake Schema in data warehousing? Which one is generally preferred for BI workloads, and why?\n",
    "\n",
    "**Purpose of Dimensional Schemas:**\n",
    "Both schemas organize data for analytical queries by separating **facts** (measurable events like sales, clicks) from **dimensions** (descriptive context like time, product, customer). This structure optimizes for:\n",
    "- Fast aggregations and filtering\n",
    "- Intuitive business modeling\n",
    "- Efficient joins for common query patterns\n",
    "\n",
    "**Star Schema:**\n",
    "- Fact table at center, connected directly to denormalized dimension tables\n",
    "- Dimensions are flat (no normalization)\n",
    "- Fewer joins required for queries\n",
    "- Some data redundancy in dimensions\n",
    "\n",
    "```text\n",
    "        [Date Dim]\n",
    "             |\n",
    "[Product Dim]—[FACT: Sales]—[Customer Dim]\n",
    "             |\n",
    "        [Store Dim]\n",
    "```\n",
    "\n",
    "**Snowflake Schema:**\n",
    "- Dimensions are normalized into sub-dimensions\n",
    "- Reduces data redundancy\n",
    "- More tables, more joins required\n",
    "\n",
    "```\n",
    "[Category]—[Product Dim]—[FACT: Sales]—[Customer Dim]—[City]—[Country]\n",
    "```\n",
    "\n",
    "**Comparison:**\n",
    "\n",
    "| Aspect | Star Schema | Snowflake Schema |\n",
    "|--------|-------------|------------------|\n",
    "| Joins | Fewer (faster queries) | More (complex queries) |\n",
    "| Storage | More redundant | More normalized |\n",
    "| Query Performance | Better | Slower |\n",
    "| Maintenance | Easier | More complex |\n",
    "| ETL Complexity | Simpler loads | More transformation |\n",
    "\n",
    "**Preferred for BI Workloads: Star Schema**\n",
    "\n",
    "**Reasons:**\n",
    "1. **Query Performance**: BI tools generate SQL that benefits from fewer joins; star schema queries are faster\n",
    "2. **Simplicity**: Business users and BI tools understand flat dimensions more easily\n",
    "3. **Aggregation Speed**: Pre-aggregated, denormalized dimensions speed up common GROUP BY operations\n",
    "4. **Storage is Cheap**: Modern systems make redundancy less of a concern than query speed\n",
    "5. **BI Tool Optimization**: Most BI tools (Tableau, Power BI, Looker) are optimized for star schema patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "/*\n",
    "## Tables\n",
    "\n",
    "**fct_ride**\n",
    "    - ride_id\n",
    "    - user_id\n",
    "    - vehicle_id\n",
    "    - ride_type (carpool or regular)\n",
    "    - start_time\n",
    "    - end_time\n",
    "\n",
    "**dim_vehicle**\n",
    "    - vehicle_id\n",
    "    - vehicle_type\n",
    "    - model\n",
    "    - capacity\n",
    "*/\n",
    "\n",
    "\n",
    "-- Question 1: Percentage of rides that are carpools\n",
    "SELECT \n",
    "    ROUND(\n",
    "        COUNT(CASE WHEN ride_type = 'carpool' THEN 1 END) * 100.0 / COUNT(*), \n",
    "        2\n",
    "    ) AS carpool_percentage\n",
    "FROM fct_ride;\n",
    "\n",
    "-- Question 2: What percentage of vehicles had more carpool rides than regular rides?\n",
    "WITH vehicle_ride_counts AS (\n",
    "    SELECT \n",
    "        vehicle_id,\n",
    "        COUNT(CASE WHEN ride_type = 'carpool' THEN 1 END) AS carpool_count,\n",
    "        COUNT(CASE WHEN ride_type = 'regular' THEN 1 END) AS regular_count\n",
    "    FROM fct_ride\n",
    "    GROUP BY vehicle_id\n",
    ")\n",
    "SELECT \n",
    "    ROUND(\n",
    "        COUNT(CASE WHEN carpool_count > regular_count THEN 1 END) * 100.0 / COUNT(*),\n",
    "        2\n",
    "    ) AS percentage_vehicles_more_carpools\n",
    "FROM vehicle_ride_counts;\n",
    "\n",
    "-- Question 3: Which vehicle had the highest total usage time?\n",
    "-- (Usage time = duration between start_time and end_time)\n",
    "SELECT \n",
    "    fr.vehicle_id,\n",
    "    dv.vehicle_type,\n",
    "    dv.model,\n",
    "    SUM(EXTRACT(EPOCH FROM (fr.end_time - fr.start_time))) / 3600 AS total_usage_hours\n",
    "FROM fct_ride fr\n",
    "JOIN dim_vehicle dv ON fr.vehicle_id = dv.vehicle_id\n",
    "GROUP BY fr.vehicle_id, dv.vehicle_type, dv.model\n",
    "ORDER BY total_usage_hours DESC\n",
    "LIMIT 1;\n",
    "\n",
    "-- Alternative for Question 3 if timestamps are stored differently:\n",
    "-- (Use this if end_time and start_time are DATETIME/TIMESTAMP types)\n",
    "SELECT \n",
    "    fr.vehicle_id,\n",
    "    dv.vehicle_type,\n",
    "    dv.model,\n",
    "    SUM(TIMESTAMPDIFF(SECOND, fr.start_time, fr.end_time)) / 3600 AS total_usage_hours\n",
    "FROM fct_ride fr\n",
    "JOIN dim_vehicle dv ON fr.vehicle_id = dv.vehicle_id\n",
    "GROUP BY fr.vehicle_id, dv.vehicle_type, dv.model\n",
    "ORDER BY total_usage_hours DESC\n",
    "LIMIT 1;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
