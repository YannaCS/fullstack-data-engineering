{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interview Practice Questions\n",
    "\n",
    "### Concept Questions\n",
    "\n",
    "#### 1. **Explain the WebSocket protocol and how it differs from HTTP polling and long polling**\n",
    "\n",
    "WebSocket is a persistent, bidirectional, full-duplex communication protocol over single TCP.\n",
    "\n",
    "**Differences**:\n",
    "- **HTTP Polling**: Client repeatedly requests server at intervals\n",
    "  - High latency, high server load, wasted requests\n",
    "  \n",
    "- **Long Polling**: Server holds request until data available\n",
    "  - Medium latency, medium load, reconnection overhead\n",
    "  \n",
    "- **WebSocket**: Persistent connection\n",
    "  - Very low latency, low load, true real-time\n",
    "  - Connection stays open, either side can send anytime\n",
    "\n",
    "**When to use WebSocket**: Chat apps, live feeds, collaborative tools, gaming\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **What caching strategy would you use for frequently accessed but slowly changing data?**\n",
    "\n",
    "**Cache-Aside** with long TTL (Time To Live)\n",
    "\n",
    "**Reasoning**:\n",
    "- Data changes slowly → Can cache for long periods (hours/days)\n",
    "- Frequently accessed → High cache hit ratio\n",
    "- Cache-Aside is simple and most common\n",
    "\n",
    "**Alternative**: Write-Through if need strong consistency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **Explain the difference between cache-aside, write-through, and write-behind caching patterns**\n",
    "\n",
    "\n",
    "**Cache-Aside (Lazy Loading)**:\n",
    "- Read from cache → Miss → Read DB → Update cache\n",
    "- Pros: Simple, only caches what's needed\n",
    "- Cons: 3 trips on miss, data can be stale(not up-to-date)\n",
    "- Use: Most common, default choice\n",
    "\n",
    "**Write-Through**:\n",
    "- Write to cache AND DB simultaneously\n",
    "- Pros: Cache always in sync, fast reads\n",
    "- Cons: Slow writes, caches all data\n",
    "- Use: Read-heavy after writes, need consistency\n",
    "\n",
    "**Write-Behind (Write-Back)**:\n",
    "- Write to cache first, DB later (async)\n",
    "- Pros: Very fast writes, can batch\n",
    "- Cons: Data loss risk if cache crashes\n",
    "- Use: Need ultra-low write latency, can tolerate loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. **Describe the differences between RabbitMQ, Kafka, and SQS in terms of use cases and guarantees**\n",
    "\n",
    "\n",
    "**RabbitMQ** (Traditional Message Broker):\n",
    "- **Use case**: Task queues, job processing, microservices RPC\n",
    "- **Guarantees**: At-most-once or at-least-once\n",
    "- Performance: ~20K msg/sec\n",
    "- Ordering: Yes (per queue)\n",
    "- Replay: No\n",
    "- Best for: Traditional pub/sub, task distribution\n",
    "\n",
    "**Kafka** (Distributed Streaming):\n",
    "- **Use case**: Event streaming, log aggregation, real-time analytics\n",
    "- **Guarantees**: At-least-once, exactly-once possible\n",
    "- Performance: 1M+ msg/sec\n",
    "- Ordering: Yes (per partition)\n",
    "- Replay: Yes (time-based retention)\n",
    "- Best for: High throughput, event sourcing, big data\n",
    "\n",
    "**AWS SQS** (Cloud Queue Service):\n",
    "- **Use case**: Simple queues, AWS ecosystem, serverless\n",
    "- **Guarantees**: At-least-once\n",
    "- Performance: Variable (AWS managed)\n",
    "- Ordering: Best effort (FIFO queues available)\n",
    "- Replay: No\n",
    "- Best for: AWS integration, managed service, simplicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. **What are message queues and why are they important in distributed systems?**\n",
    "\n",
    "Message queues enable asynchronous communication between services.   \n",
    "Has two patterns, point-to-point, publish-and-subscribe.\n",
    "\n",
    "**Importance**:\n",
    "1. **Decoupling**: Services don't need to know about each other\n",
    "2. **Reliability**: Retry failed tasks, don't lose messages\n",
    "3. **Scalability**: Add more workers to process faster\n",
    "4. **Load Leveling**: Handle traffic spikes by queuing\n",
    "5. **Fault Tolerance**: Messages persist if consumer crashes\n",
    "\n",
    "**Example**: E-commerce order processing\n",
    "\n",
    "```text\n",
    "[Web Server] → [Order Queue] → [Payment Worker]\n",
    "                             → [Inventory Worker]\n",
    "                             → [Email Worker]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. **How would you implement a retry mechanism with exponential backoff for failed message processing?**\n",
    "\n",
    "- Use a retry loop that increases the wait time after each failure (e.g., 1s → 2s → 4s). \n",
    "- Store the retry count with the message, \n",
    "- and after each failed attempt, delay the next retry using exponential backoff. \n",
    "- If it exceeds the max retries, send the message to a dead-letter queue.\n",
    "\n",
    "**Why Exponential Backoff?**\n",
    "- Avoid overwhelming failing service\n",
    "- Give system time to recover\n",
    "- Jitter prevents thundering herd problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. **Explain the concept of dead letter queues and when you'd use them**\n",
    "\n",
    "Dead Letter Queue (DLQ) = Queue for messages that fail processing repeatedly\n",
    "\n",
    "**Use Cases**:\n",
    "- Message fails after max retries\n",
    "- Message is malformed/invalid\n",
    "- Processing timeout exceeded\n",
    "- Consumer repeatedly crashes on specific message\n",
    "\n",
    "**Benefits**:\n",
    "- Don't lose failed messages\n",
    "- Debug issues later (inspect failed messages)\n",
    "- Prevent blocking main queue\n",
    "- Alert on DLQ growth\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. **How does FastAPI handle synchronous functions differently?**\n",
    "\n",
    "FastAPI runs synchronous (def) functions in a threadpool, while asynchronous (async def) functions run directly in the event loop.   \n",
    "\n",
    "So:   \n",
    "- Sync functions → executed in a worker thread so they don’t block the main event loop.\n",
    "- Async functions → executed as coroutines, giving better concurrency.\n",
    "\n",
    "This allows FastAPI to handle both types efficiently.   \n",
    "\n",
    "**Rule of Thumb**:\n",
    "- Use `async def` for I/O operations (DB, API calls, file reads)\n",
    "- Use `def` for CPU-intensive operations (avoid blocking event loop)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Challenge: Rate Limiter\n",
    "\n",
    "./RateLimiter\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
